{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6310af32-3f1a-4af4-9190-22688605cc5a",
   "metadata": {},
   "source": [
    "### importing icevision for dataset loading and model training and other libraries for coco creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "033b6e27-d4c3-4fc5-9250-3ea2d6a2b461",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import ceruleanml.data as data\n",
    "import json\n",
    "import os\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "import skimage as ski"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb615a8b-1fbb-4903-9f2b-6665016ac02c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_data_path = os.path.join(os.path.abspath(os.getcwd()),\"../../data/cerulean_v2_example/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea27a9d9-1eff-4492-84cc-28851fbf0401",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path(ml_data_path)\n",
    "layer_pths = list(path.glob(\"assets_test1_png/*\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b6c00b9-4b75-40f8-91b2-95ffe0d868de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import skimage.io as skio\n",
    "\n",
    "arr = skio.imread(layer_pths[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "558b6253-5010-4336-913e-e06b9d6d82ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_layer_of_class(arr, r,g,b):\n",
    "    return np.logical_and.reduce([arr[:,:,0]==r,arr[:,:,1]==g,arr[:,:,2]==b]).any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a49c263f-3188-433f-bed9-78929441a5b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_layer_cls(arr, class_mapping):\n",
    "    for cls in class_mapping.keys():\n",
    "        if is_layer_of_class(arr, *class_mapping[cls]):\n",
    "            return cls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a1e04287-2e3a-47b4-89fd-617a53fbae30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for pth in layer_pths:\n",
    "#     arr = skio.imread(pth)\n",
    "#     if len(arr.shape) == 2:\n",
    "#         print(pth)\n",
    "#     else:\n",
    "#         print(get_layer_cls(arr, class_mapping), os.path.basename(pth))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "236248f2-56e5-4bcf-aca2-ef2b5e9366b1",
   "metadata": {},
   "source": [
    "### Making a COCO Dataset for Mask-RCNN, converting set of instance layers per scenes from annotations to COCO labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "efacc6ca-1d8e-43c0-bffb-5d423ba979b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycococreatortools import pycococreatortools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f4ccdeb9-661e-475d-8b03-9548ce193934",
   "metadata": {},
   "outputs": [],
   "source": [
    "info = {\n",
    "    \"description\": \"Cerulean Dataset V2\",\n",
    "    \"url\": \"none\",\n",
    "    \"version\": \"1.0\",\n",
    "    \"year\": 2021,\n",
    "    \"contributor\": \"Skytruth\",\n",
    "    \"date_created\": \"2022/2/23\"\n",
    "}\n",
    "\n",
    "licenses = [\n",
    "    {\n",
    "        \"url\": \"none\",\n",
    "        \"id\": 1,\n",
    "        \"name\": \"CeruleanDataset V2\"\n",
    "    }\n",
    "]\n",
    "categories = [{\"supercategory\":\"slick\", \"id\":1,\"name\":\"infra_slick\"},\n",
    "              {\"supercategory\":\"slick\", \"id\":2,\"name\":\"natural_seep\"},\n",
    "              {\"supercategory\":\"slick\", \"id\":3,\"name\":\"coincident_vessel\"},\n",
    "              {\"supercategory\":\"slick\", \"id\":4,\"name\":\"recent_vessel\"},\n",
    "              {\"supercategory\":\"slick\", \"id\":5,\"name\":\"old_vessel\"},\n",
    "              {\"supercategory\":\"slick\", \"id\":6,\"name\":\"ambiguous\"}]\n",
    "\n",
    "coco_output = {\n",
    "    \"info\": info,\n",
    "    \"licenses\": licenses,\n",
    "    \"images\": [],\n",
    "    \"annotations\": [],\n",
    "    \"categories\": categories\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4cdb3bc4-1d20-4fe7-b563-496d7babf6e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = skio.imread(layer_pths[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "20cafdf7-c794-48c9-a71a-951a1479638a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tiled_arr = data.reshape_split(arr, (512, 512))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "09ec9da0-2cc2-4248-9866-11c54e45d43f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tiles_n, _, _ = tiled_arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9384b478-426e-4a67-9d61-a19827ea74fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0\n",
      "1 1\n",
      "2 2\n",
      "3 3\n",
      "4 4\n",
      "5 5\n",
      "6 6\n",
      "7 7\n",
      "8 8\n"
     ]
    }
   ],
   "source": [
    "for i in range(tiles_n:\n",
    "    print(i,j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d163227-05d6-400b-933b-31b7f91f602a",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_id = 1\n",
    "segmentation_id = 1\n",
    "\n",
    "images_d = []\n",
    "\n",
    "# filter for jpeg images\n",
    "for i,n in enumerate(chps):\n",
    "    images_d.append({\"file_name\": str(n), \"height\": 512, \"width\": 512, \"id\":i})\n",
    "\n",
    "    # go through each label image to extract annotation\n",
    "    image = Image.open(str(n))\n",
    "    image_info = pycococreatortools.create_image_info(\n",
    "        image_id, os.path.basename(str(n)), image.size)\n",
    "    coco_output[\"images\"].append(image_info)\n",
    "\n",
    "    annotation_filename = str(lbl_chps[i])\n",
    "    arr = np.array(Image.open(annotation_filename))\n",
    "    if 1 in arr:\n",
    "        class_id = 1\n",
    "        category_info = {\"id\":class_id,\"is_crowd\":True} # forces compressed RLE format\n",
    "    else:\n",
    "        class_id = 0\n",
    "        category_info = {\"id\":class_id,\"is_crowd\":False}\n",
    "    binary_mask = np.asarray(Image.open(annotation_filename)).astype(np.uint8)\n",
    "\n",
    "    annotation_info = pycococreatortools.create_annotation_info(\n",
    "        segmentation_id, image_id, category_info, binary_mask,\n",
    "        image.size, tolerance=0)\n",
    "\n",
    "    if annotation_info is not None:\n",
    "        coco_output[\"annotations\"].append(annotation_info)\n",
    "\n",
    "    segmentation_id = segmentation_id + 1\n",
    "\n",
    "    image_id = image_id + 1\n",
    "\n",
    "with open('{}/instances_slick_train.json'.format(path), 'w') as output_json_file:\n",
    "    json.dump(coco_output, output_json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0af76e88-330f-4d93-948a-0cd9a4537ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_map = ClassMap([\"oil_slick\"])\n",
    "class_map # https://airctic.github.io/icedata/dataset_voc_nb/#define-class_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b112b8-a3d5-49d1-8983-8a5c908baa94",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = parsers.COCOMaskParser(f'{path}/instances_slick_train.json', img_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad2f6e7a-8c1d-4bc1-aa35-331d6e27767e",
   "metadata": {},
   "source": [
    "### Parsing works! we're just trying to test if this trains and evaluates correctly, it's ok if many of these instances don't look like instances for now since the dataset was made for semantic segmentation\n",
    "\n",
    "It's possible icevision is filtering out all negative samples here during autofixing, which we can check. Our most useful samples will include non-background class hard negatives and positives anyway"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc0d401a-a667-4a8b-84e7-86711cb949cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse the annotations to create the train and validation records\n",
    "train_records, valid_records = parser.parse()\n",
    "x=show_records(train_records[:3], ncols=3, class_map=class_map)\n",
    "plt.savefig(\"train_slick_examples.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d97cdfc-1647-4f60-8c2c-bc1dcc4509fd",
   "metadata": {},
   "source": [
    "Normalizing is best practice and necessary for icevision to propoerly display predicition results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d7bbf0f-f603-4ae1-8e7c-d0620204fd95",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tfms = tfms.A.Adapter(\n",
    "    [\n",
    "        tfms.A.Normalize(),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d73d6aa-b3cf-4bb7-bfad-f13b9864d06b",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_tfms = tfms.A.Adapter([*tfms.A.resize_and_pad(size=512), tfms.A.Normalize()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5fea564-f22a-4fda-b003-135bf0f2a89c",
   "metadata": {},
   "source": [
    "sourced from: https://airctic.com/0.8.1/getting_started_instance_segmentation/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "078fd20b-4ed7-4b5a-aad2-26f9a6365ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds.records.autofix??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92349ee5-2dd6-40e7-85f5-18f388958cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = Dataset(train_records, train_tfms)\n",
    "valid_ds = Dataset(valid_records, valid_tfms)\n",
    "\n",
    "train_dl = model_type.train_dl(train_ds, batch_size=8, num_workers=6, shuffle=True) # adjust num_workers for your processor count\n",
    "valid_dl = model_type.valid_dl(valid_ds, batch_size=8, num_workers=6, shuffle=False)\n",
    "\n",
    "model = model_type.model(backbone=backbone(pretrained=False), num_classes=len(parser.class_map))\n",
    "\n",
    "metrics = [COCOMetric(metric_type=COCOMetricType.mask, print_summary=False)]\n",
    "\n",
    "learn = model_type.fastai.learner(dls=[train_dl, valid_dl], model=model, metrics=metrics)\n",
    "\n",
    "lr = learn.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96aae8b0-8b1a-4ecd-a2b2-8b00562a1b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27791bf2-ae0a-4592-af2a-99a9185f77e6",
   "metadata": {},
   "source": [
    "The suggested learning rate makes getting to higher confidence predictions take too long. We picked the learning rate arbitrarily below to speed up getting to losses closer to .5 instead of greater than 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8352a54b-26c8-48bf-91cc-97696cf45f0c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "learn.fine_tune(30,2.511886486900039e-03)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58dc1747-fb70-49a4-bac1-142c01c74e7e",
   "metadata": {},
   "source": [
    "a TODO is to debug the COCOMetric, it should not be -1 given that we are now acheiving detections that intersect with groundtruth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae2c23c8-762f-4c2e-890b-ca92ee85fe80",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"approximate time to train 30 epochs in minutes: {25*30/60}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9b181c1-7747-4b44-b8ea-ad1cc82f5b37",
   "metadata": {},
   "source": [
    "The predictions above .7 confidence that roughly line up with groundtruth demonstrates that icevision-trained models can produce predictions that look like they are headed in the correct direction, even for an imperfect training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4529311f-7a75-4992-a92b-156e44e87832",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_type.show_results??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14fdb279-777f-4116-ac32-74c0cdad5999",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d40d656-f929-4c1a-84ce-82a4fd29852c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x = model_type.show_results(model, valid_ds, detection_threshold=.6)\n",
    "plt.savefig(\"inference_results.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "197e9de8-40cd-4f58-b3da-7aaab73eae48",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_results??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff2d097-ec7b-44c6-8a62-774ddda1cba1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:fastai2]",
   "language": "python",
   "name": "conda-env-fastai2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
