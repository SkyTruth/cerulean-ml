{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6310af32-3f1a-4af4-9190-22688605cc5a",
   "metadata": {},
   "source": [
    "### importing icevision for dataset loading and model training and other libraries for coco creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "033b6e27-d4c3-4fc5-9250-3ea2d6a2b461",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "from PIL import Image\n",
    "from pathlib import Path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb615a8b-1fbb-4903-9f2b-6665016ac02c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_data_path = os.path.join(os.path.abspath(os.getcwd()),\"../../data/cerulean_v2_example/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea27a9d9-1eff-4492-84cc-28851fbf0401",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path(ml_data_path)\n",
    "layer_pths = list(path.glob(\"assets_test1_png/*\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b6c00b9-4b75-40f8-91b2-95ffe0d868de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import skimage.io as skio\n",
    "\n",
    "arr = skio.imread(layer_pths[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f366344a-1970-49b1-88a1-162abb964397",
   "metadata": {},
   "outputs": [],
   "source": [
    "import skimage as ski"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "892a132b-ff2b-47eb-8eb2-2236febe87f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_mapping = {\"Infrastructure\": (0,0,255),\n",
    "                \"Natural Seep\":(0,255,0),\n",
    "                \"Coincident Vessel\":(255,0,0),\n",
    "                \"Recent Vessel\":(255,255,0),\n",
    "                \"Old Vessel\": (255,0, 255),\n",
    "                \"Ambiguous\": (255,255,255),\n",
    "                \"Hard Negatives\":(0,255,255)}\n",
    "# Hard Neg is overloaded with overlays but they shouldn't be exported during annotation\n",
    "# Hard Neg is just a class that we will use to measure performance gains metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "558b6253-5010-4336-913e-e06b9d6d82ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_layer_of_class(arr, r,g,b):\n",
    "    return np.logical_and.reduce([arr[:,:,0]==r,arr[:,:,1]==g,arr[:,:,2]==b]).any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a49c263f-3188-433f-bed9-78929441a5b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_layer_cls(arr, class_mapping):\n",
    "    for cls in class_mapping.keys():\n",
    "        if is_layer_of_class(arr, *class_mapping[cls]):\n",
    "            return cls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e04287-2e3a-47b4-89fd-617a53fbae30",
   "metadata": {},
   "outputs": [],
   "source": [
    "for pth in layer_pths:\n",
    "    arr = skio.imread(pth)\n",
    "    if len(arr.shape) == 2:\n",
    "        print(pth)\n",
    "    else:\n",
    "        print(get_layer_cls(arr, class_mapping), os.path.basename(pth))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "236248f2-56e5-4bcf-aca2-ef2b5e9366b1",
   "metadata": {},
   "source": [
    "### Making a COCO Dataset for Mask-RCNN, converting set of instance layers per scenes from annotations to COCO labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efacc6ca-1d8e-43c0-bffb-5d423ba979b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycococreatortools import pycococreatortools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ccdeb9-661e-475d-8b03-9548ce193934",
   "metadata": {},
   "outputs": [],
   "source": [
    "info = {\n",
    "    \"description\": \"Cerulean Dataset V2\",\n",
    "    \"url\": \"none\",\n",
    "    \"version\": \"1.0\",\n",
    "    \"year\": 2021,\n",
    "    \"contributor\": \"Skytruth\",\n",
    "    \"date_created\": \"2022/2/23\"\n",
    "}\n",
    "\n",
    "licenses = [\n",
    "    {\n",
    "        \"url\": \"none\",\n",
    "        \"id\": 1,\n",
    "        \"name\": \"CeruleanDataset V2\"\n",
    "    }\n",
    "]\n",
    "categories = [{\"supercategory\":\"slick\", \"id\":1,\"name\":\"infra_slick\"},\n",
    "              {\"supercategory\":\"slick\", \"id\":2,\"name\":\"natural_seep\"},\n",
    "              {\"supercategory\":\"slick\", \"id\":3,\"name\":\"coincident_vessel\"},\n",
    "              {\"supercategory\":\"slick\", \"id\":4,\"name\":\"recent_vessel\"},\n",
    "              {\"supercategory\":\"slick\", \"id\":5,\"name\":\"old_vessel\"},\n",
    "              {\"supercategory\":\"slick\", \"id\":6,\"name\":\"ambiguous\"}]\n",
    "\n",
    "coco_output = {\n",
    "    \"info\": info,\n",
    "    \"licenses\": licenses,\n",
    "    \"images\": [],\n",
    "    \"annotations\": [],\n",
    "    \"categories\": categories\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cdb3bc4-1d20-4fe7-b563-496d7babf6e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = skio.imread(layer_pths[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8796e324-9573-418f-b9cb-8bc1d1ff0c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_l_total(chip_l, img_l):\n",
    "    \"\"\"find the total amount of padding that needs to occur \n",
    "    for an array with length img_l to be tiled to a chip size with a length chip_l\"\"\"\n",
    "    return chip_l* (1 - (img_l/chip_l - img_l//chip_l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "242cc9be-ed90-4a0c-b647-d354580fe1c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.floor(pad_l_total(512, arr.shape[0])/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed7fed3-c05d-40dd-ba9b-d209a0621844",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.ceil(pad_l_total(512, arr.shape[0])/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20cafdf7-c794-48c9-a71a-951a1479638a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape_split(image: np.ndarray, kernel_size: tuple):\n",
    "\n",
    "    img_height, img_width = image.shape\n",
    "    tile_height, tile_width = kernel_size\n",
    "    pad_height = pad_l_total(tile_height, img_height)\n",
    "    pad_width = pad_l_total(tile_width, img_width)\n",
    "    pad_height_up = np.floor(pad_height)\n",
    "    pad_height_down = np.ceil(pad_height)\n",
    "    pad_width_up = np.floor(pad_width)\n",
    "    pad_width_down = np.ceil(pad_width)\n",
    "    image_padded = np.pad(image, ((pad_height_up, pad_height_down), pad_width_up, pad_width_down), mode=\"constant\", constant_values=0)\n",
    "    img_height, img_width = image_padded.shape\n",
    "    tiled_array = image_padded.reshape(img_height // tile_height,\n",
    "                                tile_height,\n",
    "                                img_width // tile_width,\n",
    "                                tile_width, 1)\n",
    "    tiled_array = tiled_array.swapaxes(1, 2)\n",
    "    return tiled_array\n",
    "\n",
    "tiled_arr = reshape_split(arr, (512, 512))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f11ffd51-00aa-4f0a-924a-ca1c28fe910f",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr.shape[0] // 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "522138b1-ea10-402c-a091-7f3061f35d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "8 * 512 * 12 * 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "828b5fef-521f-4976-8f5c-0cc4fc098c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "z = aview.copy().reshape(-1, wx, wy) #to match expected output\n",
    "print(z.shape, z.dtype) # z.shape should be (num_patches, 288, 288)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d163227-05d6-400b-933b-31b7f91f602a",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_id = 1\n",
    "segmentation_id = 1\n",
    "\n",
    "images_d = []\n",
    "\n",
    "# filter for jpeg images\n",
    "for i,n in enumerate(chps):\n",
    "    images_d.append({\"file_name\": str(n), \"height\": 512, \"width\": 512, \"id\":i})\n",
    "\n",
    "    # go through each label image to extract annotation\n",
    "    image = Image.open(str(n))\n",
    "    image_info = pycococreatortools.create_image_info(\n",
    "        image_id, os.path.basename(str(n)), image.size)\n",
    "    coco_output[\"images\"].append(image_info)\n",
    "\n",
    "    annotation_filename = str(lbl_chps[i])\n",
    "    arr = np.array(Image.open(annotation_filename))\n",
    "    if 1 in arr:\n",
    "        class_id = 1\n",
    "        category_info = {\"id\":class_id,\"is_crowd\":True} # forces compressed RLE format\n",
    "    else:\n",
    "        class_id = 0\n",
    "        category_info = {\"id\":class_id,\"is_crowd\":False}\n",
    "    binary_mask = np.asarray(Image.open(annotation_filename)).astype(np.uint8)\n",
    "\n",
    "    annotation_info = pycococreatortools.create_annotation_info(\n",
    "        segmentation_id, image_id, category_info, binary_mask,\n",
    "        image.size, tolerance=0)\n",
    "\n",
    "    if annotation_info is not None:\n",
    "        coco_output[\"annotations\"].append(annotation_info)\n",
    "\n",
    "    segmentation_id = segmentation_id + 1\n",
    "\n",
    "    image_id = image_id + 1\n",
    "\n",
    "with open('{}/instances_slick_train.json'.format(path), 'w') as output_json_file:\n",
    "    json.dump(coco_output, output_json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0af76e88-330f-4d93-948a-0cd9a4537ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_map = ClassMap([\"oil_slick\"])\n",
    "class_map # https://airctic.github.io/icedata/dataset_voc_nb/#define-class_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b112b8-a3d5-49d1-8983-8a5c908baa94",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = parsers.COCOMaskParser(f'{path}/instances_slick_train.json', img_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad2f6e7a-8c1d-4bc1-aa35-331d6e27767e",
   "metadata": {},
   "source": [
    "### Parsing works! we're just trying to test if this trains and evaluates correctly, it's ok if many of these instances don't look like instances for now since the dataset was made for semantic segmentation\n",
    "\n",
    "It's possible icevision is filtering out all negative samples here during autofixing, which we can check. Our most useful samples will include non-background class hard negatives and positives anyway"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc0d401a-a667-4a8b-84e7-86711cb949cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse the annotations to create the train and validation records\n",
    "train_records, valid_records = parser.parse()\n",
    "x=show_records(train_records[:3], ncols=3, class_map=class_map)\n",
    "plt.savefig(\"train_slick_examples.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d97cdfc-1647-4f60-8c2c-bc1dcc4509fd",
   "metadata": {},
   "source": [
    "Normalizing is best practice and necessary for icevision to propoerly display predicition results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d7bbf0f-f603-4ae1-8e7c-d0620204fd95",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tfms = tfms.A.Adapter(\n",
    "    [\n",
    "        tfms.A.Normalize(),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d73d6aa-b3cf-4bb7-bfad-f13b9864d06b",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_tfms = tfms.A.Adapter([*tfms.A.resize_and_pad(size=512), tfms.A.Normalize()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5fea564-f22a-4fda-b003-135bf0f2a89c",
   "metadata": {},
   "source": [
    "sourced from: https://airctic.com/0.8.1/getting_started_instance_segmentation/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "078fd20b-4ed7-4b5a-aad2-26f9a6365ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds.records.autofix??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92349ee5-2dd6-40e7-85f5-18f388958cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = Dataset(train_records, train_tfms)\n",
    "valid_ds = Dataset(valid_records, valid_tfms)\n",
    "\n",
    "train_dl = model_type.train_dl(train_ds, batch_size=8, num_workers=6, shuffle=True) # adjust num_workers for your processor count\n",
    "valid_dl = model_type.valid_dl(valid_ds, batch_size=8, num_workers=6, shuffle=False)\n",
    "\n",
    "model = model_type.model(backbone=backbone(pretrained=False), num_classes=len(parser.class_map))\n",
    "\n",
    "metrics = [COCOMetric(metric_type=COCOMetricType.mask, print_summary=False)]\n",
    "\n",
    "learn = model_type.fastai.learner(dls=[train_dl, valid_dl], model=model, metrics=metrics)\n",
    "\n",
    "lr = learn.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96aae8b0-8b1a-4ecd-a2b2-8b00562a1b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27791bf2-ae0a-4592-af2a-99a9185f77e6",
   "metadata": {},
   "source": [
    "The suggested learning rate makes getting to higher confidence predictions take too long. We picked the learning rate arbitrarily below to speed up getting to losses closer to .5 instead of greater than 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8352a54b-26c8-48bf-91cc-97696cf45f0c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "learn.fine_tune(30,2.511886486900039e-03)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58dc1747-fb70-49a4-bac1-142c01c74e7e",
   "metadata": {},
   "source": [
    "a TODO is to debug the COCOMetric, it should not be -1 given that we are now acheiving detections that intersect with groundtruth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae2c23c8-762f-4c2e-890b-ca92ee85fe80",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"approximate time to train 30 epochs in minutes: {25*30/60}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9b181c1-7747-4b44-b8ea-ad1cc82f5b37",
   "metadata": {},
   "source": [
    "The predictions above .7 confidence that roughly line up with groundtruth demonstrates that icevision-trained models can produce predictions that look like they are headed in the correct direction, even for an imperfect training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4529311f-7a75-4992-a92b-156e44e87832",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_type.show_results??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14fdb279-777f-4116-ac32-74c0cdad5999",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d40d656-f929-4c1a-84ce-82a4fd29852c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x = model_type.show_results(model, valid_ds, detection_threshold=.6)\n",
    "plt.savefig(\"inference_results.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "197e9de8-40cd-4f58-b3da-7aaab73eae48",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_results??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff2d097-ec7b-44c6-8a62-774ddda1cba1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:fastai2]",
   "language": "python",
   "name": "conda-env-fastai2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
