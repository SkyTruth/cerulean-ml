{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from fastai.vision.all import *\n",
        "from fastai.callback.fp16 import *\n",
        "import torch\n",
        "import wandb\n",
        "from fastai.callback.wandb import WandbCallback\n",
        "\n",
        "from icevision.data import Dataset\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "assert torch.cuda.is_available(), \"WARNING: No GPU currently available\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from ceruleanml.data import class_list\n",
        "from ceruleanml.learner_config import (\n",
        "    memtile_size,\n",
        "    rrctile_size,\n",
        "    run_list,\n",
        "    final_px,\n",
        "    classes_to_keep,\n",
        "    get_tfms,\n",
        "    wd,\n",
        "    record_collection_train,\n",
        "    record_collection_val,\n",
        "    record_collection_test,\n",
        "    model_name,\n",
        "    num_workers,\n",
        "    model_type,\n",
        "    aux_layers\n",
        ")\n",
        "run_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "config = {\n",
        "    'memtile_size': memtile_size,\n",
        "    'rrctile_size': rrctile_size,\n",
        "    'run_list': run_list,\n",
        "    'final_px': final_px,\n",
        "    'classes_to_keep': classes_to_keep,\n",
        "    'weight_decay': wd,\n",
        "    'num_workers': num_workers,\n",
        "    'train_record_count': len(record_collection_train),\n",
        "    'val_record_count': len(record_collection_val),\n",
        "    'test_record_count': len(record_collection_test),\n",
        "    'model_type': model_type,\n",
        "    'aux_layers': aux_layers,\n",
        "    'model_name': model_name,\n",
        "}\n",
        "\n",
        "wandb.init(project='cv3', entity=\"skytruth\", config=config, name=model_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "bs_d ={512:8, 256:16, 224:16, 128:32, 64:64} # Batch Size for each image size\n",
        "lr_d = {512:1e-3, 256:1e-3, 224:1e-3, 128:1e-3, 64:1e-3} # Learning Rate for each image size\n",
        "model_dict = {\"resnet18\": resnet18, \"resnet34\": resnet34, \"convnext_small\":convnext_small, \"convnext_large\":convnext_large}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "splitter = FuncSplitter(lambda o: \"val\" in str(o.filepath.parent.parent.stem))\n",
        "\n",
        "def get_image(record):\n",
        "    if len(aux_layers)==3:\n",
        "        return record.load().img\n",
        "    elif len(aux_layers)==1:\n",
        "        return record.load().img.split()[0].convert('L')\n",
        "    else:\n",
        "        raise(\"Layer count not Supported\")\n",
        "\n",
        "def get_mask(record):\n",
        "    return generate_flattened_mask_array(record.load())\n",
        "\n",
        "def generate_flattened_mask_array(record):\n",
        "    # Extract necessary information from the record\n",
        "    string_labels = record.detection.labels\n",
        "    if not string_labels:\n",
        "        return np.zeros(record.common.img_size, dtype=np.uint8)\n",
        "    class_map = record.detection.class_map\n",
        "    labels = np.array([class_map.get_by_name(label) for label in string_labels], dtype=np.uint8)\n",
        "    masks = record.detection.mask_array.data\n",
        "    \n",
        "    # Broadcast labels to match the shape of masks and compute the weighted masks\n",
        "    weighted_masks = masks * labels[:, np.newaxis, np.newaxis]\n",
        "    \n",
        "    # Take the maximum along the first dimension\n",
        "    flattened_mask = np.max(weighted_masks, axis=0)\n",
        "    \n",
        "    return flattened_mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "r = Dataset(record_collection_train)[6]\n",
        "fig, axs = plt.subplots(1, 2, figsize=(12, 6))\n",
        "axs[0].imshow(get_image(r))\n",
        "axs[1].imshow(get_mask(r))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "cbs = [\n",
        "    WandbCallback(log_model=True),\n",
        "    # ShortEpochCallback(pct=0.1, short_valid=True), \n",
        "    # EarlyStoppingCallback(min_delta=.0001, patience=20),\n",
        "    TerminateOnNaNCallback(), \n",
        "    GradientAccumulation(256), \n",
        "    GradientClip(), \n",
        "    SaveModelCallback(), \n",
        "    ShowGraphCallback(),\n",
        "    MixedPrecision(), # I'm used to this being a .to_fp() on a learner, rather than a callback???\n",
        "    ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_seg_dls(size):\n",
        "    PIL_type = PILImageBW if len(aux_layers)==1 else PILImage\n",
        "    batch_tfms, item_tfms = get_tfms(reduced_resolution_tile_size = size)\n",
        "    seg_dblock = DataBlock(\n",
        "            blocks=(ImageBlock(PIL_type), MaskBlock(codes=classes_to_keep)), # ImageBlock is RGB by default, uses PIL\n",
        "            getters=[get_image, get_mask],\n",
        "            splitter=splitter,\n",
        "            batch_tfms=[*batch_tfms],\n",
        "            item_tfms=[*item_tfms]\n",
        "        )\n",
        "    dls = seg_dblock.dataloaders(source=[r for r in record_collection_train+record_collection_val], batch_size=bs_d[size], verbose=False).to(device)\n",
        "    return dls\n",
        "\n",
        "dls = get_seg_dls(final_px)\n",
        "# dls.show_batch()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dls = get_seg_dls(final_px)\n",
        "dls.show_batch()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "loss_func = CrossEntropyLossFlat(axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "body = create_body(model_dict[model_type](), n_in=len(aux_layers), pretrained=True)\n",
        "body = body[0] if 'convnext' in model_type else body #when using convnext models use body[0]\n",
        "model = DynamicUnet(body, n_out=len(classes_to_keep), img_size=(final_px, final_px)) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "learner = Learner(dls=dls, model=model, loss_func=loss_func, cbs=cbs, lr=lr_d[final_px], wd=wd, metrics=[DiceMulti(), foreground_acc])\n",
        "learner.to(device);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "start_new = True\n",
        "load_model_name = False\n",
        "\n",
        "if start_new:\n",
        "    print(\"Starting from scratch\")\n",
        "    learner.save(\"model\")\n",
        "elif load_model_name:\n",
        "    print(f\"Loading {load_model_name}\")\n",
        "    learner.load(load_model_name)\n",
        "    learner.save(\"model\")\n",
        "else:\n",
        "    print(\"Continuing current training session\")\n",
        "    learner.load(\"model\")\n",
        "    # export_scripted_model(learner)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from datetime import datetime\n",
        "from ceruleanml.inference import save_fastai_model_state_dict_and_tracing\n",
        "\n",
        "def export_scripted_model(learner, model_name):\n",
        "    if not os.path.exists(\"/root/experiments/cv3/\"):\n",
        "        os.makedirs(\"/root/experiments/cv3/\")\n",
        "    dateTimeObj = datetime.now()\n",
        "    timestampStr = dateTimeObj.strftime(\"%Y_%m_%d_%H_%M_%S\")\n",
        "    experiment_dir =  Path(f'/root/experiments/cv3/{timestampStr}_{model_name}_unet/')\n",
        "    experiment_dir.mkdir(exist_ok=True)\n",
        "    print(experiment_dir)\n",
        "    save_fastai_model_state_dict_and_tracing(learner, learner.dls, model_name, experiment_dir) # XXX Ethan need to check this swap works"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def set_encoder_state(learner,frozen=False):\n",
        "    state = \"Unfreezing\" if not frozen else \"Freezing\"\n",
        "    encoder_layers = learner.model[0]\n",
        "    num_params = sum(p.numel() for p in encoder_layers.parameters())\n",
        "    full_num_params = sum(p.numel() for p in learner.model.parameters())\n",
        "\n",
        "    print(state, num_params, 'encoder parameters out of', full_num_params,'total parameters')\n",
        "    for param in encoder_layers.parameters():\n",
        "        param.requires_grad = not frozen"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "running_total_epochs = {}\n",
        "for size, epochs, is_frozen in run_list:\n",
        "    print(\"PR: Starting from running total\", running_total_epochs)\n",
        "    print(\"PR: image size\", size)\n",
        "    print(\"PR: epochs\", epochs)\n",
        "    print(\"PR: encoder is\", is_frozen)\n",
        "    \n",
        "    frozen = is_frozen == 'frozen'\n",
        "    learner.dls = get_seg_dls(size)\n",
        "    set_encoder_state(learner, frozen=frozen)\n",
        "    learner.fit_one_cycle(epochs)\n",
        "\n",
        "    running_total_epochs[size] = sum(filter(None,[running_total_epochs.get(size),epochs]))\n",
        "    learner.save(model_name)\n",
        "    export_scripted_model(learner, model_name)\n",
        "\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "learner.show_results()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# wandb.finish()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
