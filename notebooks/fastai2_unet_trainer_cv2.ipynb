{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ceruleanml import data\n",
    "from ceruleanml import evaluation\n",
    "from ceruleanml import preprocess\n",
    "from fastai.data.block import DataBlock\n",
    "from fastai.vision.data import ImageBlock, MaskBlock\n",
    "from fastai.vision.augment import aug_transforms, Resize\n",
    "from fastai.vision.learner import unet_learner\n",
    "from fastai.data.transforms import IndexSplitter\n",
    "from fastai.metrics import DiceMulti\n",
    "from ceruleanml.coco_load_fastai import record_collection_to_record_ids, get_image_path, record_to_mask\n",
    "from torchvision.models import resnet18, resnet34, resnet50\n",
    "from fastai.callback.fp16 import MixedPrecision\n",
    "from fastai.callback.tensorboard import TensorBoardCallback\n",
    "from fastai.vision.core import PILImageBW\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "import os, random\n",
    "from icevision.visualize import show_data\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.callback.tracker import EarlyStoppingCallback, SaveModelCallback"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parsing COCO Dataset with Icevision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_map = {v: k for k, v in data.class_mapping_coco_inv.items()}\n",
    "class_ints = list(range(1, len(list(class_map.keys())[:-1]) + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with_context=False\n",
    "mount_path = \"/root/\"\n",
    "train_set = \"train-no-context-512\"\n",
    "tiled_images_folder_train = \"tiled_images_no_context\"\n",
    "json_name_train = \"instances_TiledCeruleanDatasetV2NoContextFiles.json\"\n",
    "\n",
    "coco_json_path_train = f\"{mount_path}/partitions/{train_set}/{json_name_train}\"\n",
    "tiled_images_folder_train = f\"{mount_path}/partitions/{train_set}/{tiled_images_folder_train}\"\n",
    "val_set = \"val-no-context-512\"\n",
    "tiled_images_folder_val= \"tiled_images_no_context\"\n",
    "json_name_val = \"instances_TiledCeruleanDatasetV2NoContextFiles.json\"\n",
    "coco_json_path_val= f\"{mount_path}/partitions/{val_set}/{json_name_val}\"\n",
    "tiled_images_folder_val = f\"{mount_path}/partitions/{val_set}/{tiled_images_folder_val}\"\n",
    "\n",
    "#with aux files\n",
    "# with_context=True\n",
    "# mount_path = \"/root/\"\n",
    "# train_set = \"train-with-context-512\"\n",
    "# tiled_images_folder_train = \"tiled_images\"\n",
    "# json_name_train = \"instances_TiledCeruleanDatasetV2.json\"\n",
    "\n",
    "# coco_json_path_train = f\"{mount_path}/partitions/{train_set}/{json_name_train}\"\n",
    "# tiled_images_folder_train = f\"{mount_path}/partitions/{train_set}/{tiled_images_folder_train}\"\n",
    "# val_set = \"val-with-context-512\"\n",
    "# tiled_images_folder_val= \"tiled_images\"\n",
    "# json_name_val = \"instances_TiledCeruleanDatasetV2.json\"\n",
    "# coco_json_path_val= f\"{mount_path}/partitions/{val_set}/{json_name_val}\"\n",
    "# tiled_images_folder_val = f\"{mount_path}/partitions/{val_set}/{tiled_images_folder_val}\"\n",
    "\n",
    "bs=16\n",
    "size=128\n",
    "n=\"all\"\n",
    "arch=34\n",
    "\n",
    "class_map = {v: k for k, v in data.class_mapping_coco_inv.items()}\n",
    "class_ints = list(range(1, len(list(class_map.keys())[:-1]) + 1))\n",
    "negative_sample_count = 0\n",
    "negative_sample_count_val = 40\n",
    "area_thresh = 10\n",
    "\n",
    "# f\"{mount_path}/partitions/val/instances_tiled_cerulean_train_v2.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## looking at area distribution to find area threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# df = preprocess.get_area_df(coco_json_path_train, tiled_images_folder_train)\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "record_collection_with_negative_small_filtered_train = preprocess.load_set_record_collection(\n",
    "    coco_json_path_train, tiled_images_folder_train, area_thresh, negative_sample_count, preprocess=False\n",
    ")\n",
    "record_ids_train = record_collection_to_record_ids(record_collection_with_negative_small_filtered_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "record_collection_with_negative_small_filtered_val = preprocess.load_set_record_collection(\n",
    "    coco_json_path_val, tiled_images_folder_val, area_thresh, negative_sample_count_val, preprocess=False\n",
    ")\n",
    "record_ids_val = record_collection_to_record_ids(record_collection_with_negative_small_filtered_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(set(record_ids_train)) + len(set(record_ids_val)) == len(record_ids_train) + len(record_ids_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val_record_ids = record_ids_train + record_ids_val\n",
    "combined_record_collection = record_collection_with_negative_small_filtered_train + record_collection_with_negative_small_filtered_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_val_indices(combined_ids, val_ids):\n",
    "    return list(range(len(combined_ids)))[-len(val_ids):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#show_data.show_records(random.choices(combined_train_records, k=9), ncols=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constructing a FastAI DataBlock that uses parsed COCO Dataset from icevision parser. aug_transforms can only be used with_context=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_indices = get_val_indices(train_val_record_ids, record_ids_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_by_record_id(record_id):\n",
    "    return get_image_path(combined_record_collection, record_id)\n",
    "\n",
    "def get_mask_by_record_id(record_id):\n",
    "    return record_to_mask(combined_record_collection, record_id)\n",
    "\n",
    "batch_transfms = [*aug_transforms(flip_vert=True, max_warp=0.1, size=size)]\n",
    "coco_seg_dblock = DataBlock(\n",
    "        blocks=(ImageBlock, MaskBlock(codes=class_ints)), # ImageBlock is RGB by default, uses PIL\n",
    "        get_x=get_image_by_record_id,\n",
    "        splitter=IndexSplitter(val_indices),\n",
    "        get_y=get_mask_by_record_id,\n",
    "        batch_tfms=batch_transfms,\n",
    "        n_inp=1\n",
    "    )\n",
    "\n",
    "\n",
    "dls = coco_seg_dblock.dataloaders(source=train_val_record_ids, batch_size=bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls.show_batch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fastai2 Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dateTimeObj = datetime.now()\n",
    "timestampStr = dateTimeObj.strftime(\"%d_%b_%Y_%H_%M_%S\")\n",
    "experiment_dir =  Path(f'{mount_path}/experiments/cv2/'+timestampStr+'_fastai_unet/')\n",
    "experiment_dir.mkdir(exist_ok=True)\n",
    "print(experiment_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "archs = {18: resnet18, 34: resnet34, 50: resnet50}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = dls.one_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removed these callbacks since they cause this error: https://forums.fast.ai/t/learner-object-has-no-attribute-recorder/46328/18\n",
    "# SaveModelCallback(monitor=\"valid_loss\", with_opt=True), \n",
    "# EarlyStoppingCallback(monitor='valid_loss', min_delta=0.005, patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.metrics import Dice, DiceMulti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cbs = [TensorBoardCallback(projector=False, trace_model=False), \n",
    "       SaveModelCallback(monitor=\"valid_loss\", with_opt=True),\n",
    "       EarlyStoppingCallback(monitor='valid_loss', min_delta=0.005, patience=5) ]\n",
    "\n",
    "learner = unet_learner(dls, archs[arch], metrics=[DiceMulti, Dice],\n",
    "                       model_dir=experiment_dir, n_out=7,\n",
    "                       cbs=cbs) #cbs=cbs# SaveModelCallback saves model when there is improvement\n",
    "# lr = learner.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dice_multi changes a little bit when training with fewer samples. but not with more samples???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size=128\n",
    "n=\"all\"\n",
    "bs=16\n",
    "arch=34"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"size\", size)\n",
    "print(\"batch size\", bs)\n",
    "print(\"arch\", arch)\n",
    "print(\"n chips\", n)\n",
    "print(\"epoch\", 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "learner.fine_tune(5, 2e-4, freeze_epochs=1) # cbs=cbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "learner.show_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Everything below here needs to be debugged, confusion matrix error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# validation = learner.validate()  \n",
    "# there's a strange bug here where an internal method is not found that should be found \n",
    "# for the Callback class. seems like a verison mismatch issue. happens if any callback included"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size=512\n",
    "# savename = f'test_6batch_{arch}_{size}_{round(validation[1],3)}.pt'\n",
    "savename = f'test_6batch_{arch}_{size}.pt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We save the best model in a variety of formats for loading later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ceruleanml.inference import save_fastai_model_state_dict_and_tracing, load_tracing_model, test_tracing_model_one_batch, logits_to_classes\n",
    "\n",
    "state_dict_pth, tracing_model_gpu_pth, tracing_model_cpu_pth  = save_fastai_model_state_dict_and_tracing(learner, dls, savename, experiment_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#import pdb\n",
    "#learn.show_results(max_n=4, figsize=(20,20), vmin=0, vmax=3)\n",
    "\n",
    "\n",
    "# Model Inference and Result Evaluation\n",
    "\n",
    "import skimage.io as skio\n",
    "import numpy as np\n",
    "val_record_ids = record_collection_to_record_ids(record_collection_with_negative_small_filtered_val)\n",
    "pred_arrs = []\n",
    "val_arrs = []\n",
    "for v, i in zip(range(len(record_ids_val)), record_ids_val):\n",
    "    v = record_collection_with_negative_small_filtered_val[v]\n",
    "    v_masks = v.detection.masks[0].to_mask(v.common.height,v.common.width).data\n",
    "    p = get_image_path(record_collection_with_negative_small_filtered_val,i)\n",
    "    arr = skio.imread(p)\n",
    "    # necessary for 1 channel input since fastai uses PIL during predict\n",
    "    class_pred = learner.predict(np.squeeze(arr))\n",
    "    class_pred = class_pred[0].cpu().detach().numpy()\n",
    "    pred_arrs.append(class_pred)\n",
    "    val_arrs.append(v_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm, f1 = evaluation.cm_f1(val_arrs, pred_arrs, 6, mount_path) # todo add normalize false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner = torch.load(\"/root/data/experiments/cv2/10_May_2022_18_02_59_fastai_unet/18_64_0.493.pkl\")\n",
    "\n",
    "\n",
    "import skimage.io as skio\n",
    "val_record_ids = record_collection_to_record_ids(valid_records)\n",
    "pred_arrs = []\n",
    "with learner.no_logging():\n",
    "    for i in val_record_ids:\n",
    "        p = get_image_path(valid_records,i)\n",
    "        arr = skio.imread(p)\n",
    "        pred_arr = learner.predict(arr)\n",
    "        pred_arrs.append(pred_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# this results in vm dying, not just kernel crash\n",
    "# coco_seg_dblock = DataBlock(\n",
    "#     blocks=(ImageBlock, MaskBlock(codes=class_ints)),\n",
    "#     get_x=get_image_by_record_id,\n",
    "#     get_y=get_mask_by_record_id,\n",
    "#     n_inp=1,\n",
    "# )\n",
    "\n",
    "# dls = coco_seg_dblock.dataloaders(source=record_ids, batch_size=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = learner.get_preds(dl=dls[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.get_preds??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(pred_arrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_label,prediction_arr, activations = pred_arrs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skio.imshow(target_label.cpu().detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skio.imshow(base_img.cpu().detach().numpy()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skio.imshow(base_img.cpu().detach().numpy()[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skio.imshow(base_img.cpu().detach().numpy()[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skio.imshow(base_img.cpu().detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array([      60.73,       190.3,      4.3598]) # means\n",
    "array([     16.099,      17.846,       9.603]) # stats"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "fastai2_training.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:fastai2]",
   "language": "python",
   "name": "conda-env-fastai2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
