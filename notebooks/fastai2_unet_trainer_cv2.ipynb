{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment Notebook for CV2\n",
    "\n",
    "This notebook is a development workspace to add or subtract features during model development. Once a set of changes is ready to be experimented with, it should be cleaned, copied and saved to a new notebook that can be run end to end with no errors and committed in a separate git commit. For example, \"fastai2_unet_trainer_cv2-1channel-baseline.ipynb\" is an experiment that should not be changed in version control once committed but cells can be edited to inspect the results on your local machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import resnet18, resnet34, resnet50\n",
    "bs_d ={512:4, 256:32, 224:32, 128:64, 64:256} # Batch Size for each image size\n",
    "lr_d = {512:3e-4, 256:1e-3, 224:3e-3, 128:3e-3, 64:1e-2} # Learning Rate for each image size\n",
    "mins_d = {512:5.88, 256:1.5, 224:1.15, 128:0.4, 64:0.2} # Duration of epoch for each image size\n",
    "arch_d = {18: resnet18, 34: resnet34, 50: resnet50} # ResNet Architectures\n",
    "\n",
    "run_list = [[224, 11]]*20 # List of tuples, where the tuples are [px size, training time in minutes]\n",
    "with_context = False\n",
    "fp16 = False\n",
    "n = \"all\"\n",
    "arch = 34\n",
    "negative_sample_count = 0\n",
    "negative_sample_count_val = 0\n",
    "area_thresh = 10\n",
    "remap_dict = {\n",
    "    \"ambiguous\": None,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ceruleanml import data\n",
    "from ceruleanml import evaluation\n",
    "from ceruleanml import preprocess\n",
    "from ceruleanml import inference\n",
    "from fastai.data.block import DataBlock\n",
    "from fastai.vision.data import ImageBlock, MaskBlock\n",
    "from fastai.vision.augment import aug_transforms, Resize\n",
    "from fastai.vision.learner import unet_learner\n",
    "from fastai.data.transforms import IndexSplitter\n",
    "from fastai.metrics import DiceMulti, Dice, accuracy_multi, PrecisionMulti, RecallMulti\n",
    "from ceruleanml.coco_load_fastai import record_collection_to_record_ids, get_image_path, record_to_mask\n",
    "from fastai.callback.fp16 import MixedPrecision\n",
    "from fastai.callback.tensorboard import TensorBoardCallback\n",
    "from fastai.vision.core import PILImageBW\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "import os, random\n",
    "from icevision.visualize import show_data\n",
    "import torch\n",
    "from fastai.callback.tracker import EarlyStoppingCallback, SaveModelCallback\n",
    "import skimage.io as skio\n",
    "import numpy as np\n",
    "from math import log\n",
    "import glob\n",
    "from google.cloud import storage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Parsing COCO Dataset\n",
    "if with_context:\n",
    "    train_set = \"train-with-context-512\"\n",
    "    tiled_images_folder_train = \"tiled_images\"\n",
    "    json_name_train = \"instances_TiledCeruleanDatasetV2.json\"\n",
    "    val_set = \"val-with-context-512\"\n",
    "    tiled_images_folder_val= \"tiled_images\"\n",
    "    json_name_val = \"instances_TiledCeruleanDatasetV2.json\"\n",
    "else:\n",
    "    train_set = \"train-no-context-512\"\n",
    "    tiled_images_folder_train = \"tiled_images_no_context\"\n",
    "    json_name_train = \"instances_TiledCeruleanDatasetV2NoContextFiles.json\"\n",
    "    val_set = \"val-no-context-512\"\n",
    "    tiled_images_folder_val= \"tiled_images_no_context\"\n",
    "    json_name_val = \"instances_TiledCeruleanDatasetV2NoContextFiles.json\"\n",
    "\n",
    "mount_path = \"/root/\"\n",
    "coco_json_path_train = f\"{mount_path}/partitions/{train_set}/{json_name_train}\"\n",
    "tiled_images_folder_train = f\"{mount_path}/partitions/{train_set}/{tiled_images_folder_train}\"\n",
    "coco_json_path_val= f\"{mount_path}/partitions/{val_set}/{json_name_val}\"\n",
    "tiled_images_folder_val = f\"{mount_path}/partitions/{val_set}/{tiled_images_folder_val}\"\n",
    "\n",
    "class_map = {v: k for k, v in data.class_mapping_coco_inv.items()}\n",
    "class_ints = list(range(1, len(list(class_map.keys())[:-1]) + 1))\n",
    "\n",
    "record_collection_with_negative_small_filtered_train = preprocess.load_set_record_collection(\n",
    "    coco_json_path_train, tiled_images_folder_train, area_thresh, negative_sample_count, preprocess=False, remap_dict=remap_dict\n",
    ")\n",
    "record_ids_train = record_collection_to_record_ids(record_collection_with_negative_small_filtered_train)\n",
    "\n",
    "record_collection_with_negative_small_filtered_val = preprocess.load_set_record_collection(\n",
    "    coco_json_path_val, tiled_images_folder_val, area_thresh, negative_sample_count_val, preprocess=False, remap_dict=remap_dict\n",
    ")\n",
    "record_ids_val = record_collection_to_record_ids(record_collection_with_negative_small_filtered_val)\n",
    "\n",
    "assert len(set(record_ids_train)) + len(set(record_ids_val)) == len(record_ids_train) + len(record_ids_val)\n",
    "\n",
    "train_val_record_ids = record_ids_train + record_ids_val\n",
    "combined_record_collection = record_collection_with_negative_small_filtered_train + record_collection_with_negative_small_filtered_val\n",
    "\n",
    "def get_val_indices(combined_ids, val_ids):\n",
    "    return list(range(len(combined_ids)))[-len(val_ids):]\n",
    "\n",
    "#show_data.show_records(random.choices(combined_train_records, k=9), ncols=3)\n",
    "\n",
    "### Constructing a FastAI DataBlock that uses parsed COCO Dataset from icevision parser. aug_transforms can only be used with_context=True\n",
    "\n",
    "val_indices = get_val_indices(train_val_record_ids, record_ids_val)\n",
    "\n",
    "def get_image_by_record_id(record_id):\n",
    "    return get_image_path(combined_record_collection, record_id)\n",
    "\n",
    "def get_mask_by_record_id(record_id):\n",
    "    return record_to_mask(combined_record_collection, record_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fastai2 Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dateTimeObj = datetime.now()\n",
    "timestampStr = dateTimeObj.strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "experiment_dir =  Path(f'{mount_path}/experiments/cv2/'+timestampStr+'_fastai_unet/')\n",
    "experiment_dir.mkdir(exist_ok=True)\n",
    "print(experiment_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_size = run_list[0][0]\n",
    "batch_transfms = [*aug_transforms(flip_vert=True, max_rotate=180, max_warp=0.1, size=init_size)]\n",
    "coco_seg_dblock = DataBlock(\n",
    "        blocks=(ImageBlock, MaskBlock(codes=class_ints)), # ImageBlock is RGB by default, uses PIL\n",
    "        get_x=get_image_by_record_id,\n",
    "        splitter=IndexSplitter(val_indices),\n",
    "        get_y=get_mask_by_record_id,\n",
    "        batch_tfms=batch_transfms,\n",
    "        item_tfms = Resize(init_size),\n",
    "        n_inp=1\n",
    "    )\n",
    "dls = coco_seg_dblock.dataloaders(source=train_val_record_ids, batch_size=bs_d[init_size])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cbs = [TensorBoardCallback(projector=False, trace_model=False), \n",
    "       # SaveModelCallback(monitor=\"valid_loss\", with_opt=True),\n",
    "       # EarlyStoppingCallback(monitor='valid_loss', min_delta=0.005, patience=10) \n",
    "       ]\n",
    "\n",
    "learner = unet_learner(dls, arch_d[arch], metrics=[DiceMulti],\n",
    "                       model_dir=experiment_dir, n_out=7,\n",
    "                       cbs=cbs) #cbs=cbs# SaveModelCallback saves model when there is improvement\n",
    "\n",
    "if fp16:\n",
    "       learner = learner.to_fp16()\n",
    "\n",
    "running_total_epochs = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for size, total_train_time in run_list:\n",
    "    epochs = max(int(total_train_time/mins_d[size]), 1)\n",
    "    bs = bs_d[size]\n",
    "    lr = lr_d[size]\n",
    "\n",
    "    batch_transfms = [*aug_transforms(flip_vert=True, max_rotate=180, max_warp=0.1, size=size)]\n",
    "    coco_seg_dblock = DataBlock(\n",
    "            blocks=(ImageBlock, MaskBlock(codes=class_ints)), # ImageBlock is RGB by default, uses PIL\n",
    "            get_x=get_image_by_record_id,\n",
    "            splitter=IndexSplitter(val_indices),\n",
    "            get_y=get_mask_by_record_id,\n",
    "            batch_tfms=batch_transfms,\n",
    "            item_tfms = Resize(size),\n",
    "            n_inp=1\n",
    "        )\n",
    "    dls = coco_seg_dblock.dataloaders(source=train_val_record_ids, batch_size=bs)\n",
    "    learner.dls = dls\n",
    "    print(f\"Training time is: {total_train_time} minutes\")\n",
    "    print(\"starting from running total\", running_total_epochs)\n",
    "    print(\"image size\", size)\n",
    "    print(\"batch size\", bs)\n",
    "    print(\"arch\", arch)\n",
    "    print(\"lr\", lr)\n",
    "    print(\"n chips\", n)\n",
    "    print(\"context\", with_context)\n",
    "    print(\"epochs\", epochs)\n",
    "\n",
    "    learner.fine_tune(epochs, lr, freeze_epochs=0) # cbs=cbs\n",
    "\n",
    "    running_total_epochs[size] = sum(filter(None,[running_total_epochs.get(size),epochs]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save *.pt file locally\n",
    "savename = f'{size}_{running_total_epochs[size]}_{bs}_{arch}_{lr}_{round(learner.validate()[1],3)}.pt'\n",
    "learner.export(experiment_dir/(savename[:-3]+\".pkl\"))\n",
    "inference.save_fastai_model_state_dict_and_tracing(learner, dls, savename, experiment_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload *.pt folder to GCS\n",
    "def upload_from_directory(directory_path: str, dest_bucket_name: str, dest_blob_name: str):\n",
    "    rel_paths = glob.glob(directory_path + '/**', recursive=True)\n",
    "    bucket = storage.Client().bucket(dest_bucket_name)\n",
    "    for local_file in rel_paths:\n",
    "        if os.path.isfile(local_file):\n",
    "            remote_path = f'{dest_blob_name}/{local_file[len(directory_path)+1:]}'\n",
    "            blob = bucket.blob(remote_path)\n",
    "            blob.upload_from_filename(local_file)\n",
    "\n",
    "\n",
    "upload_from_directory(str(experiment_dir), 'ceruleanml', str(experiment_dir.relative_to('/root')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensorboard --logdir=/root/work/notebooks/runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.show_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_list = [[512, 120]] # List of tuples, where the tuples are [px size, training time in minutes]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Inference and Result Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation.get_cm_for_learner(dls, learner, mount_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "validation = learner.validate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We save the best model in a variety of formats for loading later. Eval on Torchscript model still being debugged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_template = f'test_{bs}_{arch}_{size}_{round(validation[1],3)}_{epochs}.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ceruleanml.inference import save_fastai_model_state_dict_and_tracing, load_tracing_model, test_tracing_model_one_batch, logits_to_classes\n",
    "\n",
    "state_dict_pth, tracing_model_gpu_pth, tracing_model_cpu_pth  = save_fastai_model_state_dict_and_tracing(learner, dls, save_template, experiment_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load(tracing_model_cpu_pth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cm_for_torchscript_model(dls, model, save_path):\n",
    "\"\"\"\n",
    "the torchscript model when it is loaded operates on batches, not individual images\n",
    "this doesn't support eval on negative samples if they are in the dls, \n",
    "since val masks don't exist with neg samples. need to be constructed with np.zeros\n",
    "\n",
    "returns cm and f1 score\n",
    "\"\"\"\n",
    "val_arrs = []\n",
    "class_preds = []\n",
    "for batch_tuple in dls.valid:\n",
    "    semantic_masks_batch = batch_tuple[1].cpu().detach().numpy()\n",
    "    class_pred_batch = model(batch_tuple[0].cpu())\n",
    "    class_pred_batch = class_pred_batch.cpu().detach().numpy()\n",
    "    val_arrs.extend(semantic_masks_batch)\n",
    "    class_preds.append(class_pred_batch)\n",
    "return evaluation.cm_f1(val_arrs, class_preds, 6, save_path) # todo add normalize false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_cm_for_torchscript_model(dls, model, mount_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# this results in vm dying, not just kernel crash\n",
    "# coco_seg_dblock = DataBlock(\n",
    "#     blocks=(ImageBlock, MaskBlock(codes=class_ints)),\n",
    "#     get_x=get_image_by_record_id,\n",
    "#     get_y=get_mask_by_record_id,\n",
    "#     n_inp=1,\n",
    "# )\n",
    "\n",
    "# dls = coco_seg_dblock.dataloaders(source=record_ids, batch_size=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = learner.get_preds(dl=dls[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.get_preds??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(pred_arrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_label,prediction_arr, activations = pred_arrs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skio.imshow(target_label.cpu().detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skio.imshow(base_img.cpu().detach().numpy()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skio.imshow(base_img.cpu().detach().numpy()[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skio.imshow(base_img.cpu().detach().numpy()[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skio.imshow(base_img.cpu().detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array([      60.73,       190.3,      4.3598]) # means\n",
    "array([     16.099,      17.846,       9.603]) # stats"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "fastai2_training.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('fastai2': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "9fbe5814291ec456a3f3d2797c8d44c497100db1aaba83677934530eb96c924b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
