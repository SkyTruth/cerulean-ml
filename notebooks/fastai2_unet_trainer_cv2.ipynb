{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment Notebook for CV2\n",
    "\n",
    "This notebook is a development workspace to add or subtract features during model development. Once a set of changes is ready to be experimented with, it should be cleaned, copied and saved to a new notebook that can be run end to end with no errors and committed in a separate git commit. For example, \"fastai2_unet_trainer_cv2-1channel-baseline.ipynb\" is an experiment that should not be changed in version control once committed but cells can be edited to inspect the results on your local machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import resnet18, resnet34, resnet50\n",
    "bs_d ={512:4, 256:32, 224:32, 128:64, 64:256}\n",
    "lr_d = {512:3e-4, 256:1e-3, 224:3e-3, 128:3e-3, 64:1e-2}\n",
    "arch_d = {18: resnet18, 34: resnet34, 50: resnet50}\n",
    "\n",
    "\n",
    "size=224\n",
    "bs = bs_d[size]\n",
    "n=\"all\"\n",
    "arch=34\n",
    "epochs = 30\n",
    "freeze = 0\n",
    "negative_sample_count = 0\n",
    "negative_sample_count_val = 0\n",
    "area_thresh = 0\n",
    "classes_to_remove=[\n",
    "    \"ambiguous\",\n",
    "    ]\n",
    "classes_to_remap ={\n",
    "    # \"old_vessel\": \"recent_vessel\",\n",
    "    # \"coincident_vessel\": \"recent_vessel\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ceruleanml import data\n",
    "from ceruleanml import evaluation\n",
    "from ceruleanml import preprocess\n",
    "from fastai.data.block import DataBlock\n",
    "from fastai.vision.data import ImageBlock, MaskBlock\n",
    "from fastai.vision.augment import aug_transforms, Resize\n",
    "from fastai.vision.learner import unet_learner\n",
    "from fastai.data.transforms import IndexSplitter\n",
    "from fastai.metrics import DiceMulti, Dice, accuracy_multi, PrecisionMulti, RecallMulti\n",
    "from ceruleanml.coco_load_fastai import record_collection_to_record_ids, get_image_path, record_to_mask\n",
    "from fastai.callback.fp16 import MixedPrecision\n",
    "from fastai.callback.tensorboard import TensorBoardCallback\n",
    "from fastai.vision.core import PILImageBW\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "import os, random\n",
    "from icevision.visualize import show_data\n",
    "import torch\n",
    "from fastai.callback.tracker import EarlyStoppingCallback, SaveModelCallback\n",
    "import skimage.io as skio\n",
    "import numpy as np\n",
    "from math import log\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_held_scenes(f_paths):\n",
    "    held_scenes = []\n",
    "    for f_path in f_paths:\n",
    "        with open(f_path) as f:\n",
    "            data = f.read().split(\"\\n\")\n",
    "            held_scenes += [line.split(\"/\")[-1] for line in data]\n",
    "    return held_scenes\n",
    "test_scenes = f\"/root/data/partitions/test_scenes.txt\"\n",
    "val_scenes = f\"/root/data/partitions/val_scenes.txt\"\n",
    "held_scenes = get_held_scenes([test_scenes, val_scenes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if not 'this_cell_has_been_run_already' in locals():\n",
    "\n",
    "    ### Parsing COCO Dataset with Icevision\n",
    "\n",
    "    mount_path = \"/root/\"\n",
    "    train_set = \"train-with-context-512\"\n",
    "    tiled_images_folder_train = \"tiled_images\"\n",
    "    json_name_train = \"instances_TiledCeruleanDatasetV2.json\"\n",
    "\n",
    "    coco_json_path_train = f\"{mount_path}/partitions/{train_set}/{json_name_train}\"\n",
    "    tiled_images_folder_train = f\"{mount_path}/partitions/{train_set}/{tiled_images_folder_train}\"\n",
    "    val_set = \"val-with-context-512\"\n",
    "    tiled_images_folder_val= \"tiled_images\"\n",
    "    json_name_val = \"instances_TiledCeruleanDatasetV2.json\"\n",
    "    coco_json_path_val= f\"{mount_path}/partitions/{val_set}/{json_name_val}\"\n",
    "    tiled_images_folder_val = f\"{mount_path}/partitions/{val_set}/{tiled_images_folder_val}\"\n",
    "\n",
    "    ## looking at area distribution to find area threshold\n",
    "\n",
    "    # df = preprocess.get_area_df(coco_json_path_train, tiled_images_folder_train)\n",
    "    # df\n",
    "    \n",
    "    record_collection_with_negative_small_filtered_train = preprocess.load_set_record_collection(\n",
    "    coco_json_path_train, tiled_images_folder_train, area_thresh, negative_sample_count_val, preprocess=False, \n",
    "    classes_to_remap=classes_to_remap, classes_to_remove=classes_to_remove, held_scenes=held_scenes)\n",
    "    \n",
    "    record_collection_with_negative_small_filtered_val = preprocess.load_set_record_collection(\n",
    "    coco_json_path_val, tiled_images_folder_val, area_thresh, negative_sample_count_val, preprocess=True,\n",
    "    classes_to_remap=classes_to_remap, classes_to_remove=classes_to_remove)\n",
    "\n",
    "    record_ids_train = record_collection_to_record_ids(record_collection_with_negative_small_filtered_train)\n",
    "    record_ids_val = record_collection_to_record_ids(record_collection_with_negative_small_filtered_val)\n",
    "\n",
    "    assert len(set(record_ids_train)) + len(set(record_ids_val)) == len(record_ids_train) + len(record_ids_val)\n",
    "\n",
    "    train_val_record_ids = record_ids_train + record_ids_val\n",
    "    combined_record_collection = record_collection_with_negative_small_filtered_train + record_collection_with_negative_small_filtered_val\n",
    "\n",
    "    def get_val_indices(combined_ids, val_ids):\n",
    "        return list(range(len(combined_ids)))[-len(val_ids):]\n",
    "\n",
    "    #show_data.show_records(random.choices(combined_train_records, k=9), ncols=3)\n",
    "\n",
    "    ### Constructing a FastAI DataBlock that uses parsed COCO Dataset from icevision parser. aug_transforms can only be used with_context=True\n",
    "\n",
    "    val_indices = get_val_indices(train_val_record_ids, record_ids_val)\n",
    "\n",
    "    def get_image_by_record_id(record_id):\n",
    "        return get_image_path(combined_record_collection, record_id)\n",
    "\n",
    "    def get_mask_by_record_id(record_id):\n",
    "        return record_to_mask(combined_record_collection, record_id)\n",
    "\n",
    "    this_cell_has_been_run_already = True\n",
    "else:\n",
    "    print('skipped')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_transfms = [*aug_transforms(flip_vert=True, max_rotate=180, max_warp=0.1, size=size)]\n",
    "coco_seg_dblock = DataBlock(\n",
    "        blocks=(ImageBlock, MaskBlock(codes=data.class_list)), # ImageBlock is RGB by default, uses PIL\n",
    "        get_x=get_image_by_record_id,\n",
    "        splitter=IndexSplitter(val_indices),\n",
    "        get_y=get_mask_by_record_id,\n",
    "        batch_tfms=batch_transfms,\n",
    "        item_tfms = Resize(size),\n",
    "        n_inp=1\n",
    "    )\n",
    "\n",
    "\n",
    "dls = coco_seg_dblock.dataloaders(source=train_val_record_ids, batch_size=bs)\n",
    "\n",
    "# dls.show_batch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fastai2 Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dateTimeObj = datetime.now()\n",
    "timestampStr = dateTimeObj.strftime(\"%d_%b_%Y_%H_%M_%S\")\n",
    "experiment_dir =  Path(f'{mount_path}/experiments/cv2/'+timestampStr+'_fastai_unet/')\n",
    "experiment_dir.mkdir(exist_ok=True)\n",
    "print(experiment_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cbs = [TensorBoardCallback(projector=False, trace_model=False), \n",
    "       # SaveModelCallback(monitor=\"valid_loss\", with_opt=True),\n",
    "       # EarlyStoppingCallback(monitor='valid_loss', min_delta=0.005, patience=10) \n",
    "       ]\n",
    "\n",
    "learner = unet_learner(dls, arch_d[arch], metrics=[DiceMulti, Dice],\n",
    "                       model_dir=experiment_dir,\n",
    "                       cbs=cbs) #cbs=cbs# SaveModelCallback saves model when there is improvement\n",
    "# lr = learner.lr_find()\n",
    "running_total_epochs = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = lr_d[size]\n",
    "# lr = learner.lr_find()\n",
    "# lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"starting from running total\", running_total_epochs)\n",
    "print(\"size\", size)\n",
    "print(\"batch size\", bs)\n",
    "print(\"arch\", arch)\n",
    "print(\"lr\", lr)\n",
    "print(\"n chips\", n)\n",
    "print(\"epochs\", epochs)\n",
    "print(\"freeze\", freeze)\n",
    "\n",
    "learner.fine_tune(epochs, lr, freeze_epochs=freeze) # cbs=cbs\n",
    "learner.show_results()\n",
    "\n",
    "running_total_epochs[size] = sum(filter(None,[running_total_epochs.get(size),epochs,freeze]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Progressive Resizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for size in [224]*20:\n",
    "    bs = bs_d[size]\n",
    "    lr = lr_d[size]\n",
    "\n",
    "    batch_transfms = [*aug_transforms(flip_vert=True, max_rotate=180, max_warp=0.1, size=size)]\n",
    "    coco_seg_dblock = DataBlock(\n",
    "            blocks=(ImageBlock, MaskBlock(codes=data.class_list)), # ImageBlock is RGB by default, uses PIL\n",
    "            get_x=get_image_by_record_id,\n",
    "            splitter=IndexSplitter(val_indices),\n",
    "            get_y=get_mask_by_record_id,\n",
    "            batch_tfms=batch_transfms,\n",
    "            item_tfms = Resize(size),\n",
    "            n_inp=1\n",
    "        )\n",
    "    learner.dls = coco_seg_dblock.dataloaders(source=train_val_record_ids, batch_size=bs)\n",
    "    print(\"starting from running total\", running_total_epochs)\n",
    "    print(\"image size\", size)\n",
    "    print(\"batch size\", bs)\n",
    "    print(\"arch\", arch)\n",
    "    print(\"lr\", lr)\n",
    "    print(\"n chips\", n)\n",
    "    print(\"epochs\", epochs)\n",
    "    print(\"freeze\", freeze)\n",
    "\n",
    "    learner.fine_tune(epochs, lr, freeze_epochs=freeze) # cbs=cbs\n",
    "    learner.show_results()\n",
    "\n",
    "    running_total_epochs[size] = sum(filter(None,[running_total_epochs.get(size),epochs,freeze]))\n",
    "    checkpoint = learner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Inference and Result Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with learner.no_bar():\n",
    "    val_arrs = []\n",
    "    class_preds = []\n",
    "    for batch_tuple in dls.train:\n",
    "        for img, val_mask in zip(batch_tuple[0], batch_tuple[1]):\n",
    "            semantic_mask = val_mask.cpu().detach().numpy()\n",
    "            class_pred = learner.predict(img.cpu())\n",
    "            class_pred = class_pred[0].cpu().detach().numpy()\n",
    "            val_arrs.append(semantic_mask)\n",
    "            class_preds.append(class_pred)\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# inspecting preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "records_of_interest = []\n",
    "for record in record_collection_with_negative_small_filtered_train:\n",
    "    if \"S1A_IW_GRDH_1SDV_20200724T020738_20200724T020804_033590_03E494_B457\" in str(record.common.filepath):\n",
    "        records_of_interest.append(record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "arr = skio.imread(records_of_interest[0].common.filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.moveaxis(arr, 2, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = next(iter(dls.train))\n",
    "val_mask  = b[1][0]\n",
    "semantic_mask = val_mask.cpu().detach().numpy()\n",
    "img  = b[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import skimage.io as skio\n",
    "skio.imshow(semantic_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skio.imshow(np.moveaxis(img.cpu().detach().numpy(), 0, 2)[:,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "_,_,preds=learner.get_preds(dl=[b], with_decoded=True)\n",
    "dls.show_results(b, preds, max_n=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = learner.predict(img.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_loss, dice_multi, dice = learner.validate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ceruleanml.inference import save_fastai_model_state_dict_and_tracing, load_tracing_model, test_tracing_model_one_batch, logits_to_classes\n",
    "save_template = f'test_{bs}_{arch}_{size}_{round(dice_multi,3)}_{epochs}.pt'\n",
    "state_dict_pth, tracing_model_gpu_pth, tracing_model_cpu_pth  = save_fastai_model_state_dict_and_tracing(learner, dls, save_template, experiment_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp -r {experiment_dir} /root/data/experiments/cv2/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After loading numpy array batch with the shape above, import Torch and call torch.Tensor on the numpy array batch of tiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.jit.load(tracing_model_cpu_pth)\n",
    "#these are equivalent\n",
    "# inference on a tensor\n",
    "# b_result = model(b[0].cpu())\n",
    "\n",
    "# inference on numpy array converted to tensor\n",
    "b_result = model(torch.Tensor(b[0].cpu().detach().numpy())) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skio.imshow(b_result[0].sigmoid().detach().numpy()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ceruleanml.inference import logits_to_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf, classes = logits_to_classes(tile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logits_to_classes(out_batch_logits):\n",
    "    \"\"\"returns the confidence scores of the max confident classes\n",
    "    and an array of max confident class ids.\n",
    "    \"\"\"\n",
    "    probs = torch.nn.functional.softmax(out_batch_logits, dim=1)\n",
    "    conf, classes = torch.max(probs, 1)\n",
    "    return (conf, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tile.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#argmax to get category index where confidence is highest\n",
    "# confidence is returned after applying sigmoid to the logits\n",
    "# we only apply sigmoid on an individual tile from the batch!\n",
    "# tile = b_result[0,:,:,:]\n",
    "# indices = np.argmax(tile.softmax().cpu().detach().numpy(), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_thresh=.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cpu_tile_confs= tile.sigmoid().cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_conf_threshold(conf, classes, conf_threshold):\n",
    "    high_conf_mask = torch.any(torch.where(conf> conf_thresh, 1, 0), axis=0)\n",
    "    return torch.where(high_conf_mask, classes, 0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apply_conf_threshold(conf, classes, conf_thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_conf_mask = np.any(np.where(conf> conf_thresh, 1, 0), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skio.imshow(classes.cpu().detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skio.imshow(tile.cpu().detach().numpy()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skio.imshow(tile.cpu().detach().numpy()[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.class_idx_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skio.imshow(tile.cpu().detach().numpy()[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skio.imshow(conf.cpu().detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skio.imshow(np.where(high_conf_mask, classes, 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CM is bugged because predict is bugged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "evaluation.get_cm_for_learner(dls, learner, mount_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "validation = learner.validate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We save the best model in a variety of formats for loading later. Eval on Torchscript model still being debugged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_template = f'test_{bs}_{arch}_{size}_{round(validation[1],3)}_{epochs}.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ceruleanml.inference import save_fastai_model_state_dict_and_tracing, load_tracing_model, test_tracing_model_one_batch, logits_to_classes\n",
    "\n",
    "state_dict_pth, tracing_model_gpu_pth, tracing_model_cpu_pth  = save_fastai_model_state_dict_and_tracing(learner, dls, save_template, experiment_dir)\n",
    "\n",
    "model = torch.load(tracing_model_cpu_pth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cm_for_torchscript_model(dls, model, save_path):\n",
    "\"\"\"\n",
    "the torchscript model when it is loaded operates on batches, not individual images\n",
    "this doesn't support eval on negative samples if they are in the dls, \n",
    "since val masks don't exist with neg samples. need to be constructed with np.zeros\n",
    "\n",
    "returns cm and f1 score\n",
    "\"\"\"\n",
    "val_arrs = []\n",
    "class_preds = []\n",
    "for batch_tuple in dls.valid:\n",
    "    semantic_masks_batch = batch_tuple[1].cpu().detach().numpy()\n",
    "    class_pred_batch = model(batch_tuple[0].cpu())\n",
    "    class_pred_batch = class_pred_batch.cpu().detach().numpy()\n",
    "    val_arrs.extend(semantic_masks_batch)\n",
    "    class_preds.append(class_pred_batch)\n",
    "return evaluation.cm_f1(val_arrs, class_preds, save_path) # todo add normalize false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_cm_for_torchscript_model(dls, model, mount_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = learner.get_preds(dl=dls[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.get_preds??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(pred_arrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_label,prediction_arr, activations = pred_arrs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skio.imshow(target_label.cpu().detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skio.imshow(base_img.cpu().detach().numpy()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skio.imshow(base_img.cpu().detach().numpy()[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skio.imshow(base_img.cpu().detach().numpy()[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skio.imshow(base_img.cpu().detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array([      60.73,       190.3,      4.3598]) # means\n",
    "array([     16.099,      17.846,       9.603]) # stats"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "fastai2_training.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "a91ad926ed9e7e813fca12d5ce40250effd42c93c85625329945ee278a46be73"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
