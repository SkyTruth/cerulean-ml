{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See scripts/ to run this notebook experiment as a script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ceruleanml import data\n",
    "from ceruleanml import evaluation\n",
    "from ceruleanml import preprocess\n",
    "from ceruleanml.inference import save_fastai_model_state_dict_and_tracing, load_tracing_model, test_tracing_model_one_batch, logits_to_classes\n",
    "from fastai.data.block import DataBlock\n",
    "from fastai.vision.data import ImageBlock, MaskBlock\n",
    "from fastai.vision.augment import aug_transforms, Resize\n",
    "from fastai.vision.learner import unet_learner\n",
    "from fastai.data.transforms import IndexSplitter\n",
    "from fastai.metrics import DiceMulti, Dice\n",
    "from ceruleanml.coco_load_fastai import record_collection_to_record_ids, get_image_path, record_to_mask\n",
    "from torchvision.models import resnet18, resnet34, resnet50\n",
    "from fastai.callback.fp16 import MixedPrecision\n",
    "from fastai.callback.tensorboard import TensorBoardCallback\n",
    "from fastai.vision.core import PILImageBW\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "import os, random\n",
    "from icevision.visualize import show_data\n",
    "import torch\n",
    "\n",
    "from fastai.callback.tracker import EarlyStoppingCallback, SaveModelCallback\n",
    "\n",
    "### Parsing COCO Dataset with Icevision\n",
    "\n",
    "with_context=False\n",
    "mount_path = \"/root/\"\n",
    "train_set = \"train-no-context-512\"\n",
    "tiled_images_folder_train = \"tiled_images_no_context\"\n",
    "json_name_train = \"instances_TiledCeruleanDatasetV2NoContextFiles.json\"\n",
    "\n",
    "coco_json_path_train = f\"{mount_path}/partitions/{train_set}/{json_name_train}\"\n",
    "tiled_images_folder_train = f\"{mount_path}/partitions/{train_set}/{tiled_images_folder_train}\"\n",
    "val_set = \"val-no-context-512\"\n",
    "tiled_images_folder_val= \"tiled_images_no_context\"\n",
    "json_name_val = \"instances_TiledCeruleanDatasetV2NoContextFiles.json\"\n",
    "coco_json_path_val= f\"{mount_path}/partitions/{val_set}/{json_name_val}\"\n",
    "tiled_images_folder_val = f\"{mount_path}/partitions/{val_set}/{tiled_images_folder_val}\"\n",
    "\n",
    "bs=8 # max\n",
    "size=512\n",
    "n=\"all\"\n",
    "arch=34\n",
    "epochs = 100\n",
    "\n",
    "negative_sample_count = 0\n",
    "negative_sample_count_val = 0\n",
    "area_thresh = 10\n",
    "\n",
    "record_collection_with_negative_small_filtered_train = preprocess.load_set_record_collection(\n",
    "    coco_json_path_train, tiled_images_folder_train, area_thresh, negative_sample_count, preprocess=False\n",
    ")\n",
    "record_ids_train = record_collection_to_record_ids(record_collection_with_negative_small_filtered_train)\n",
    "\n",
    "record_collection_with_negative_small_filtered_val = preprocess.load_set_record_collection(\n",
    "    coco_json_path_val, tiled_images_folder_val, area_thresh, negative_sample_count_val, preprocess=False\n",
    ")\n",
    "record_ids_val = record_collection_to_record_ids(record_collection_with_negative_small_filtered_val)\n",
    "\n",
    "assert len(set(record_ids_train)) + len(set(record_ids_val)) == len(record_ids_train) + len(record_ids_val)\n",
    "\n",
    "train_val_record_ids = record_ids_train + record_ids_val\n",
    "combined_record_collection = record_collection_with_negative_small_filtered_train + record_collection_with_negative_small_filtered_val\n",
    "\n",
    "def get_val_indices(combined_ids, val_ids):\n",
    "    return list(range(len(combined_ids)))[-len(val_ids):]\n",
    "\n",
    "### Constructing a FastAI DataBlock that uses parsed COCO Dataset from icevision parser. aug_transforms can only be used with_context=True\n",
    "\n",
    "val_indices = get_val_indices(train_val_record_ids, record_ids_val)\n",
    "\n",
    "def get_image_by_record_id(record_id):\n",
    "    return get_image_path(combined_record_collection, record_id)\n",
    "\n",
    "def get_mask_by_record_id(record_id):\n",
    "    return record_to_mask(combined_record_collection, record_id)\n",
    "\n",
    "batch_transfms = [*aug_transforms(flip_vert=True, max_warp=0.1, size=size)]\n",
    "coco_seg_dblock = DataBlock(\n",
    "        blocks=(ImageBlock, MaskBlock(codes=data.class_list)), # ImageBlock is RGB by default, uses PIL\n",
    "        get_x=get_image_by_record_id,\n",
    "        splitter=IndexSplitter(val_indices),\n",
    "        get_y=get_mask_by_record_id,\n",
    "        batch_tfms=batch_transfms,\n",
    "        n_inp=1\n",
    "    )\n",
    "\n",
    "\n",
    "dls = coco_seg_dblock.dataloaders(source=train_val_record_ids, batch_size=bs)\n",
    "\n",
    "### Fastai2 Trainer\n",
    "\n",
    "dateTimeObj = datetime.now()\n",
    "timestampStr = dateTimeObj.strftime(\"%d_%b_%Y_%H_%M_%S\")\n",
    "experiment_dir =  Path(f'{mount_path}/experiments/cv2/'+timestampStr+'_fastai_unet/')\n",
    "experiment_dir.mkdir(exist_ok=True)\n",
    "print(experiment_dir)\n",
    "\n",
    "archs = {18: resnet18, 34: resnet34, 50: resnet50}\n",
    "\n",
    "cbs = [TensorBoardCallback(projector=False, trace_model=False), \n",
    "       SaveModelCallback(monitor=\"valid_loss\", with_opt=True),\n",
    "       EarlyStoppingCallback(monitor='valid_loss', min_delta=0.005, patience=10) ]\n",
    "\n",
    "learner = unet_learner(dls, archs[arch], metrics=[DiceMulti, Dice],\n",
    "                       model_dir=experiment_dir, n_out=7,\n",
    "                       cbs=cbs) #cbs=cbs# SaveModelCallback saves model when there is improvement\n",
    "\n",
    "print(\"size\", size)\n",
    "print(\"batch size\", bs)\n",
    "print(\"arch\", arch)\n",
    "print(\"n chips\", n)\n",
    "print(\"epochs (with early stopping and patience=10):\", epochs)\n",
    "\n",
    "learner.fine_tune(epochs, 1e-4, freeze_epochs=1) # cbs=cbs\n",
    "\n",
    "evaluation.get_cm_for_learner(dls, learner, mount_path)\n",
    "\n",
    "validation = learner.validate()\n",
    "\n",
    "save_template = f'test_{bs}_{arch}_{size}_{round(validation[1],3)}_{epochs}.pt'\n",
    "\n",
    "state_dict_pth, tracing_model_gpu_pth, tracing_model_cpu_pth  = save_fastai_model_state_dict_and_tracing(learner, dls, save_template, experiment_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "fastai2_training.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:fastai2]",
   "language": "python",
   "name": "conda-env-fastai2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
