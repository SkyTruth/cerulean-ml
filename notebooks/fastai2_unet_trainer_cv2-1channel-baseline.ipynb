{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b90ba12553d4505861db97121306b7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3863 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "736512cbfa60472996e32d37df031781",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/352 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/fastai2/lib/python3.9/site-packages/torch/_tensor.py:1051: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  ret = func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/root/experiments/cv2/09_Jun_2022_20_44_25_fastai_unet\n",
      "size 512\n",
      "batch size 8\n",
      "arch 34\n",
      "n chips all\n",
      "epochs (with early stopping and patience=10): 100\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>dice_multi</th>\n",
       "      <th>dice</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.132062</td>\n",
       "      <td>0.096845</td>\n",
       "      <td>0.141538</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>05:42</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better model found at epoch 0 with valid_loss value: 0.09684529900550842.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/100 00:00<00:00]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>dice_multi</th>\n",
       "      <th>dice</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='52' class='' max='376' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      13.83% [52/376 00:47<04:57 0.1125]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from ceruleanml import data\n",
    "from ceruleanml import evaluation\n",
    "from ceruleanml import preprocess\n",
    "from ceruleanml.inference import save_fastai_model_state_dict_and_tracing, load_tracing_model, test_tracing_model_one_batch, logits_to_classes\n",
    "from fastai.data.block import DataBlock\n",
    "from fastai.vision.data import ImageBlock, MaskBlock\n",
    "from fastai.vision.augment import aug_transforms, Resize\n",
    "from fastai.vision.learner import unet_learner\n",
    "from fastai.data.transforms import IndexSplitter\n",
    "from fastai.metrics import DiceMulti, Dice\n",
    "from ceruleanml.coco_load_fastai import record_collection_to_record_ids, get_image_path, record_to_mask\n",
    "from torchvision.models import resnet18, resnet34, resnet50\n",
    "from fastai.callback.fp16 import MixedPrecision\n",
    "from fastai.callback.tensorboard import TensorBoardCallback\n",
    "from fastai.vision.core import PILImageBW\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "import os, random\n",
    "from icevision.visualize import show_data\n",
    "import torch\n",
    "\n",
    "from fastai.callback.tracker import EarlyStoppingCallback, SaveModelCallback\n",
    "\n",
    "### Parsing COCO Dataset with Icevision\n",
    "\n",
    "class_map = {v: k for k, v in data.class_mapping_coco_inv.items()}\n",
    "class_ints = list(range(1, len(list(class_map.keys())[:-1]) + 1))\n",
    "\n",
    "with_context=False\n",
    "mount_path = \"/root/\"\n",
    "train_set = \"train-no-context-512\"\n",
    "tiled_images_folder_train = \"tiled_images_no_context\"\n",
    "json_name_train = \"instances_TiledCeruleanDatasetV2NoContextFiles.json\"\n",
    "\n",
    "coco_json_path_train = f\"{mount_path}/partitions/{train_set}/{json_name_train}\"\n",
    "tiled_images_folder_train = f\"{mount_path}/partitions/{train_set}/{tiled_images_folder_train}\"\n",
    "val_set = \"val-no-context-512\"\n",
    "tiled_images_folder_val= \"tiled_images_no_context\"\n",
    "json_name_val = \"instances_TiledCeruleanDatasetV2NoContextFiles.json\"\n",
    "coco_json_path_val= f\"{mount_path}/partitions/{val_set}/{json_name_val}\"\n",
    "tiled_images_folder_val = f\"{mount_path}/partitions/{val_set}/{tiled_images_folder_val}\"\n",
    "\n",
    "bs=8 # max\n",
    "size=512\n",
    "n=\"all\"\n",
    "arch=34\n",
    "epochs = 100\n",
    "\n",
    "class_map = {v: k for k, v in data.class_mapping_coco_inv.items()}\n",
    "class_ints = list(range(1, len(list(class_map.keys())[:-1]) + 1))\n",
    "negative_sample_count = 0\n",
    "negative_sample_count_val = 0\n",
    "area_thresh = 10\n",
    "\n",
    "record_collection_with_negative_small_filtered_train = preprocess.load_set_record_collection(\n",
    "    coco_json_path_train, tiled_images_folder_train, area_thresh, negative_sample_count, preprocess=False\n",
    ")\n",
    "record_ids_train = record_collection_to_record_ids(record_collection_with_negative_small_filtered_train)\n",
    "\n",
    "record_collection_with_negative_small_filtered_val = preprocess.load_set_record_collection(\n",
    "    coco_json_path_val, tiled_images_folder_val, area_thresh, negative_sample_count_val, preprocess=False\n",
    ")\n",
    "record_ids_val = record_collection_to_record_ids(record_collection_with_negative_small_filtered_val)\n",
    "\n",
    "assert len(set(record_ids_train)) + len(set(record_ids_val)) == len(record_ids_train) + len(record_ids_val)\n",
    "\n",
    "train_val_record_ids = record_ids_train + record_ids_val\n",
    "combined_record_collection = record_collection_with_negative_small_filtered_train + record_collection_with_negative_small_filtered_val\n",
    "\n",
    "def get_val_indices(combined_ids, val_ids):\n",
    "    return list(range(len(combined_ids)))[-len(val_ids):]\n",
    "\n",
    "### Constructing a FastAI DataBlock that uses parsed COCO Dataset from icevision parser. aug_transforms can only be used with_context=True\n",
    "\n",
    "val_indices = get_val_indices(train_val_record_ids, record_ids_val)\n",
    "\n",
    "def get_image_by_record_id(record_id):\n",
    "    return get_image_path(combined_record_collection, record_id)\n",
    "\n",
    "def get_mask_by_record_id(record_id):\n",
    "    return record_to_mask(combined_record_collection, record_id)\n",
    "\n",
    "batch_transfms = [*aug_transforms(flip_vert=True, max_warp=0.1, size=size)]\n",
    "coco_seg_dblock = DataBlock(\n",
    "        blocks=(ImageBlock, MaskBlock(codes=class_ints)), # ImageBlock is RGB by default, uses PIL\n",
    "        get_x=get_image_by_record_id,\n",
    "        splitter=IndexSplitter(val_indices),\n",
    "        get_y=get_mask_by_record_id,\n",
    "        batch_tfms=batch_transfms,\n",
    "        n_inp=1\n",
    "    )\n",
    "\n",
    "\n",
    "dls = coco_seg_dblock.dataloaders(source=train_val_record_ids, batch_size=bs)\n",
    "\n",
    "### Fastai2 Trainer\n",
    "\n",
    "dateTimeObj = datetime.now()\n",
    "timestampStr = dateTimeObj.strftime(\"%d_%b_%Y_%H_%M_%S\")\n",
    "experiment_dir =  Path(f'{mount_path}/experiments/cv2/'+timestampStr+'_fastai_unet/')\n",
    "experiment_dir.mkdir(exist_ok=True)\n",
    "print(experiment_dir)\n",
    "\n",
    "archs = {18: resnet18, 34: resnet34, 50: resnet50}\n",
    "\n",
    "cbs = [TensorBoardCallback(projector=False, trace_model=False), \n",
    "       SaveModelCallback(monitor=\"valid_loss\", with_opt=True),\n",
    "       EarlyStoppingCallback(monitor='valid_loss', min_delta=0.005, patience=10) ]\n",
    "\n",
    "learner = unet_learner(dls, archs[arch], metrics=[DiceMulti, Dice],\n",
    "                       model_dir=experiment_dir, n_out=7,\n",
    "                       cbs=cbs) #cbs=cbs# SaveModelCallback saves model when there is improvement\n",
    "\n",
    "print(\"size\", size)\n",
    "print(\"batch size\", bs)\n",
    "print(\"arch\", arch)\n",
    "print(\"n chips\", n)\n",
    "print(\"epochs (with early stopping and patience=10):\", epochs)\n",
    "\n",
    "learner.fine_tune(epochs, 1e-4, freeze_epochs=1) # cbs=cbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "evaluation.get_cm_for_learner(dls, learner, mount_path)\n",
    "\n",
    "validation = learner.validate()\n",
    "\n",
    "save_template = f'test_{bs}_{arch}_{size}_{round(validation[1],3)}_{epochs}.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict_pth, tracing_model_gpu_pth, tracing_model_cpu_pth  = save_fastai_model_state_dict_and_tracing(learner, dls, save_template, experiment_dir)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "fastai2_training.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:fastai2]",
   "language": "python",
   "name": "conda-env-fastai2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
