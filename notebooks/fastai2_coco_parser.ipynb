{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "OlVAlUe_To6f"
   },
   "outputs": [],
   "source": [
    "import os, sys\n",
    "from shutil import copyfile\n",
    "from datetime import datetime\n",
    "import importlib\n",
    "import skimage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fastai\n",
    "from fastai.vision.all import *\n",
    "from fastai.basics import *\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from fastai.callback.fp16 import ModelToHalf\n",
    "from fastai.callback.hook import hook_output\n",
    "import tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorboard_helpers import TensorBoardBaseCallback, TensorBoardCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = 64 # Progressive resizing could happen here\n",
    "augs = aug_transforms(flip_vert=True, max_warp=0.1, size=size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CV2 Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[1mINFO    \u001b[0m\u001b[1m\u001b[0m - \u001b[1mDownloading default `.ttf` font file - SpaceGrotesk-Medium.ttf from https://raw.githubusercontent.com/airctic/storage/master/SpaceGrotesk-Medium.ttf to /root/.icevision/fonts/SpaceGrotesk-Medium.ttf\u001b[0m | \u001b[36micevision.visualize.utils\u001b[0m:\u001b[36mget_default_font\u001b[0m:\u001b[36m67\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://ultralytics.com/assets/Arial.ttf to /root/.config/Ultralytics/Arial.ttf...\n"
     ]
    }
   ],
   "source": [
    "from ceruleanml import data\n",
    "import icevision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_map = {v: k for k, v in data.class_mapping_coco_inv.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Infrastructure',\n",
       " 'Natural Seep',\n",
       " 'Coincident Vessel',\n",
       " 'Recent Vessel',\n",
       " 'Old Vessel',\n",
       " 'Ambiguous']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(class_map.keys())[:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### img tile fnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a46e5f6f802e48e898dd87a4dfa4e8ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/487 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[1mINFO    \u001b[0m\u001b[1m\u001b[0m - \u001b[1m\u001b[34m\u001b[1mAutofixing records\u001b[0m\u001b[1m\u001b[34m\u001b[0m\u001b[1m\u001b[0m | \u001b[36micevision.parsers.parser\u001b[0m:\u001b[36mparse\u001b[0m:\u001b[36m122\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c39a36de4f34a588871548413e98545",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/487 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "parser = icevision.parsers.COCOMaskParser(annotations_filepath=\"../../data/cv2_transfer/instances_slicks_test_v2.json\", img_dir=\"../../data/tiled_image_slicks_test_v2\")\n",
    "train_records = parser.parse(data_splitter=icevision.data.SingleSplitSplitter())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['common', 'detection'])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_records[0][0].as_dict().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(train_records[0])):\n",
    "    assert len(train_records[0][0].as_dict()['detection']['masks']) == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepaths = []\n",
    "record_ids = []\n",
    "for r in train_records[0]:\n",
    "    filepaths.append(r.as_dict()['common']['filepath'])\n",
    "    record_ids.append(r.as_dict()['common']['record_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'filepaths':filepaths, 'record_ids': record_ids}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6797, 7031]\n",
      "[6798, 6915, 7032]\n",
      "[6577, 6694]\n",
      "[7370, 7838]\n",
      "[7383, 7851]\n",
      "[7853, 7970]\n",
      "[7508, 7625, 7859]\n",
      "[1078, 1195]\n",
      "[649, 883]\n",
      "[779, 896]\n",
      "[8449, 8800]\n",
      "[8584, 8701]\n",
      "[8585, 8702, 8936]\n",
      "[8715, 8949]\n",
      "[9340, 9457]\n",
      "[2306, 2566, 2696]\n",
      "[2852, 2969]\n",
      "[10096, 10213]\n",
      "[10181, 10298]\n",
      "[10194, 10311]\n",
      "[3793, 3919, 4045]\n",
      "[4269, 4395]\n",
      "[3584, 3710]\n",
      "[4514, 4631]\n",
      "[4862, 4992]\n",
      "[5009, 5113, 5217]\n",
      "[5021, 5125]\n",
      "[5022, 5126]\n",
      "[5114, 5218]\n",
      "[11535, 11886]\n",
      "[11536, 11887]\n",
      "[12246, 12714]\n",
      "[12247, 12715]\n",
      "[12727, 12883]\n",
      "[13187, 13538]\n",
      "[12954, 13071, 13188, 13656]\n",
      "[13199, 13316, 13433]\n"
     ]
    }
   ],
   "source": [
    "for i in df.groupby(['filepaths'])['record_ids'].apply(list):\n",
    "    if len(i) > 1:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### need to merge potentially overlapping arrays and use id list as iterable for get_y in data block "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def record_to_np_mask(record_id_list):\n",
    "    if len(record_id_list) == 1:\n",
    "        d = record.as_dict()\n",
    "        return d['detection']['masks'][0].to_mask(d['common']['height'],d['common']['width']).data\n",
    "    elif len(record_id_list) >1:\n",
    "        arrs = []\n",
    "        for i in record_id_list:\n",
    "            d = train_records[0][i].as_dict()\n",
    "            arr = d['detection']['masks'][0].to_mask(d['common']['height'],d['common']['width']).data\n",
    "            arrs.append(arr)\n",
    "            np."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_imgs_from_records(record_collection):\n",
    "    l = []\n",
    "    for r in record_collection:\n",
    "        l.append(r.as_dict()['common']['filepath'])\n",
    "    return l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "need to build a fastai data loader that doesn't take img paths and instead tkaes in mem sparse arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_chps(path): return list(sparse_masks.keys())\n",
    "def get_lbls(fn): return sparse_masks[fn] # fn is the imge path "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m \u001b[0mMaskBlock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcodes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mSource:\u001b[0m   \n",
       "\u001b[0;32mdef\u001b[0m \u001b[0mMaskBlock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcodes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m\"A `TransformBlock` for segmentation masks, potentially with `codes`\"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mreturn\u001b[0m \u001b[0mTransformBlock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype_tfms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mPILMask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem_tfms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mAddMaskCodes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcodes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcodes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_tfms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mIntToFloatTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mFile:\u001b[0m      ~/miniconda3/envs/fastai2/lib/python3.9/site-packages/fastai/vision/data.py\n",
       "\u001b[0;31mType:\u001b[0m      function\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "MaskBlock??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'codes' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [42]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m coco_seg_dblock \u001b[38;5;241m=\u001b[39m DataBlock(blocks\u001b[38;5;241m=\u001b[39m(ImageBlock, MaskBlock(codes\u001b[38;5;241m=\u001b[39m\u001b[43mcodes\u001b[49m)),\n\u001b[1;32m      2\u001b[0m                  get_items\u001b[38;5;241m=\u001b[39mget_imgs_from_records,\n\u001b[1;32m      3\u001b[0m                  splitter\u001b[38;5;241m=\u001b[39mRandomSplitter(),\n\u001b[1;32m      4\u001b[0m                  get_y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m record: record_to_np_mask(record), \n\u001b[1;32m      5\u001b[0m                  batch_tfms\u001b[38;5;241m=\u001b[39maug_transforms(),\n\u001b[1;32m      6\u001b[0m                  n_inp\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'codes' is not defined"
     ]
    }
   ],
   "source": [
    "coco_seg_dblock = DataBlock(blocks=(ImageBlock, MaskBlock(codes=codes)),\n",
    "                 get_items=get_imgs_from_records,\n",
    "                 splitter=RandomSplitter(),\n",
    "                 get_y=lambda record: record_to_np_mask(record), \n",
    "                 batch_tfms=aug_transforms(),\n",
    "                 n_inp=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CV1 Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "uCnKPbcUZyW8"
   },
   "outputs": [],
   "source": [
    "mount_path = \"/root/data/cv1_transfer/\"\n",
    "ml_data_path = os.path.join(mount_path, \"labeled_data\")\n",
    "path = Path(ml_data_path)\n",
    "oil_chps = np.loadtxt(path/'oil_chps.txt', dtype=str)\n",
    "codes = np.loadtxt(path/'codes.txt', dtype=str)\n",
    "valid_names = np.loadtxt(path/'valid_names.txt', dtype=str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import skimage.io as skio\n",
    "import numpy as np\n",
    "import dask\n",
    "\n",
    "labels = path/\"lbl\"\n",
    "labels_no_3 = path/\"lbl_no3\"\n",
    "\n",
    "os.makedirs(labels_no_3, exist_ok=True)\n",
    "\n",
    "vals = set()\n",
    "lazy_results = []\n",
    "for i in list(labels.glob(\"*.png\"))[0:100]:\n",
    "    arr = skio.imread(i)\n",
    "    values = np.unique(arr)\n",
    "    # I think this was setting a class we didn't need to 0 \n",
    "    # for the purposes of recreating Jona's binary classifier\n",
    "    arr[arr==3] = 0\n",
    "    try:\n",
    "        lazy_result = dask.delayed(skio.imsave)(labels_no_3 / i.name, arr, check_contrast=False)\n",
    "        lazy_results.append(lazy_result)\n",
    "    except:\n",
    "        continue\n",
    "computed_results = dask.compute(*lazy_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 240,
     "status": "ok",
     "timestamp": 1632546951657,
     "user": {
      "displayName": "Jona Raphael",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjFH3JKgScTtrAcB2yttHcHQ3q_PCg3Xi9B7XE-=s64",
      "userId": "11620402000831919596"
     },
     "user_tz": 240
    },
    "id": "ub_sFHTytr1P",
    "outputId": "e91e92e9-2f5c-4cae-9adf-e562a176498c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "473"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.seed(42)\n",
    "oilless_chps = [chp for chp in get_image_files(path/'chp') if chp.stem not in oil_chps]\n",
    "density = 0\n",
    "num_oilless = density * len(oil_chps)\n",
    "mixed_chps = random.sample(oilless_chps,num_oilless) + [path/'chp'/(chp+'.png') for chp in oil_chps]\n",
    "len(mixed_chps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Background', 'Oil', 'Coincident'], dtype='<U10')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_HsNE9p2Wqep"
   },
   "outputs": [],
   "source": [
    "def get_chps(path): return mixed_chps\n",
    "def get_lbls(fn): return fn.parent.parent/\"lbl_no3\"/f\"{fn.name}\"\n",
    "def splitter_func(fn): return fn.name.rsplit('_',1)[0] in valid_names # XXX Check to make sure this should be returning True for Valid\n",
    "\n",
    "drive_files = get_chps(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "awsaMCkNijP4"
   },
   "outputs": [],
   "source": [
    "dateTimeObj = datetime.now()\n",
    "timestampStr = dateTimeObj.strftime(\"%d_%b_%Y_%H_%M_%S\")\n",
    "lcl =  Path('/root/data/experiments/cv1/'+timestampStr+'/')\n",
    "#lcl = Path(\"../out_data\")\n",
    "lcl.mkdir(exist_ok=True)\n",
    "modelpath = lcl\n",
    "\n",
    "use_lcl = False\n",
    "if use_lcl:\n",
    "  path = lcl\n",
    "  lcl_chp = path/\"chp\"\n",
    "  lcl_lbl = path/\"lbl_no3\"\n",
    "  lcl_chp.mkdir(exist_ok=True)\n",
    "  lcl_lbl.mkdir(exist_ok=True)\n",
    "  for i, f in enumerate(drive_files): # 10 minutes?!\n",
    "    if not i%50: print(i, f)\n",
    "    if not (lcl_chp/f.name).exists():\n",
    "      copyfile(f, lcl_chp/f.name)\n",
    "    if not (lcl_lbl/f.name).exists():\n",
    "      copyfile(get_lbls(f), lcl_lbl/f.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qoHswk_YP7iV"
   },
   "outputs": [],
   "source": [
    "seg_db = DataBlock(\n",
    "    blocks=(ImageBlock, MaskBlock(codes=codes)),\n",
    "    get_items = get_chps,\n",
    "    splitter=FuncSplitter(splitter_func),\n",
    "    batch_tfms=augs,\n",
    "    get_y=get_lbls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3300,
     "status": "ok",
     "timestamp": 1632546955601,
     "user": {
      "displayName": "Jona Raphael",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjFH3JKgScTtrAcB2yttHcHQ3q_PCg3Xi9B7XE-=s64",
      "userId": "11620402000831919596"
     },
     "user_tz": 240
    },
    "id": "DXMotRvjP7Za",
    "outputId": "d62fa328-7ed6-4e4e-aaae-cf201ac9bc69"
   },
   "outputs": [],
   "source": [
    "dls = SegmentationDataLoaders.from_dblock(\n",
    "    dblock = seg_db,\n",
    "    source = path,\n",
    "    path = path,\n",
    "    bs = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seg_db.summary(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "executionInfo": {
     "elapsed": 335,
     "status": "ok",
     "timestamp": 1632546955921,
     "user": {
      "displayName": "Jona Raphael",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjFH3JKgScTtrAcB2yttHcHQ3q_PCg3Xi9B7XE-=s64",
      "userId": "11620402000831919596"
     },
     "user_tz": 240
    },
    "id": "P-7SCS_V6Orz",
    "outputId": "81a80929-4c76-4333-b07c-868c6918a553"
   },
   "outputs": [],
   "source": [
    "dls.show_batch(vmin=0, vmax=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uPn56uxHDP_j"
   },
   "outputs": [],
   "source": [
    "# add best model callback saver\n",
    "# write to drive not lcl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AE9i5evdCXon"
   },
   "outputs": [],
   "source": [
    "arch = 18\n",
    "archs = {18: resnet18, 34: resnet34, 50: resnet50}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 721,
     "status": "ok",
     "timestamp": 1632546956633,
     "user": {
      "displayName": "Jona Raphael",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjFH3JKgScTtrAcB2yttHcHQ3q_PCg3Xi9B7XE-=s64",
      "userId": "11620402000831919596"
     },
     "user_tz": 240
    },
    "id": "VQDrYV4as0f4",
    "outputId": "be5c7bec-7b97-409b-dbc7-a59676fed601"
   },
   "outputs": [],
   "source": [
    "learn = unet_learner(dls, archs[arch], metrics=[Dice()], model_dir=modelpath, cbs=[MixedPrecision])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 378
    },
    "executionInfo": {
     "elapsed": 3689,
     "status": "error",
     "timestamp": 1632546972885,
     "user": {
      "displayName": "Jona Raphael",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjFH3JKgScTtrAcB2yttHcHQ3q_PCg3Xi9B7XE-=s64",
      "userId": "11620402000831919596"
     },
     "user_tz": 240
    },
    "id": "8lCi_0dct6jf",
    "outputId": "b85c39c8-6c8a-4c2b-dd2b-c0e2a5d74132",
    "tags": []
   },
   "outputs": [],
   "source": [
    "lr = learn.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cbs = [TensorBoardCallback(projector=False, trace_model=False)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Gvtui2X587kZ"
   },
   "outputs": [],
   "source": [
    "learn.fine_tune(5, 2e-4, cbs=cbs)#, cbs=SaveModelCallback(monitor='dice'))w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XERpDg9jZli1"
   },
   "outputs": [],
   "source": [
    "# learn.load(\"model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i4v3-QkSCOu0"
   },
   "outputs": [],
   "source": [
    "savename = f'{density}_{arch}_{size}_{round(learn.validate()[1],3)}.pkl'\n",
    "learn.export(f'{modelpath}/{savename}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls {modelpath}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VJQ3VVuD9rx2"
   },
   "outputs": [],
   "source": [
    "learn.show_results(max_n=4, figsize=(20,20), vmin=0, vmax=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Default path for tensorboard logs is `./runs/`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls './runs/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copy logs to appropriate exeriments folder in the mounted GCS volume."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp -R './runs/' {modelpath}'/tensorboard/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, run the following from anywhere with gcs authenticated:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tensorboard --logdir=\"/root/data/experiments/cv1/09_Mar_2022_18_32_17/tensorboard\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "fastai2_training.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:fastai2]",
   "language": "python",
   "name": "conda-env-fastai2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
